{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Science Toolbox\n",
    "#### Hugo Bowne-Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Description\n",
    "It’s time to push forward and develop your Python chops even further. There are tons of fantastic functions in Python and its library ecosystem. However, as a data scientist, you’ll constantly need to write your own functions to solve problems that are dictated by your data. You will learn the art of function writing in this first Python Data Science Toolbox course. You’ll come out of this course being able to write your very own custom functions, complete with multiple parameters and multiple return values, along with default arguments and variable-length arguments. You’ll gain insight into scoping in Python and be able to write lambda functions and handle errors in your function writing practice. And you’ll wrap up each chapter by using your new skills to write functions that analyze Twitter DataFrames.\n",
    "\n",
    "In this second Python Data Science Toolbox course, you’ll continue to build your Python data science skills. First, you’ll learn about iterators, objects you have already encountered in the context of for loops. You’ll then learn about list comprehensions, which are extremely handy tools for all data scientists working in Python. You’ll end the course by working through a case study in which you’ll apply all the techniques you learned in both parts of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Writing your own functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you’ll learn how to write simple functions, as well as functions that accept multiple arguments and return multiple values. You’ll also have the opportunity to apply these new skills to questions commonly encountered by data scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User-defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Strings in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, you learned of another standard Python datatype, __strings__. Recall that these represent textual data. To assign the string ‘DataCamp’ to a variable company, you execute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "company = 'DataCamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve also learned to use the operations + and * with strings. Unlike with numeric types such as ints and floats, the + operator concatenates strings together, while the * concatenates multiple copies of a string together. In this exercise, you will use the + and * operations on strings to answer the question below. Execute the following code in the shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "object1 = \"data\" + \"analysis\" + \"visualization\"\n",
    "\n",
    "object2 = 1 * 3\n",
    "\n",
    "object3 = \"1\" * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values in object1, object2, and object3, respectively?\n",
    "\n",
    "- object1 contains “data + analysis + visualization”, object2 contains “1*3”, object3 contains 13.\n",
    "- object1 contains “data+analysis+visualization”, object2 contains 3, object3 contains “13”.\n",
    "- object1 contains “dataanalysisvisualization”, object2 contains 3, object3 contains “111”.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Recapping built-in functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, Hugo briefly examined the return behavior of the built-in functions print() and str(). Here, you will use both functions and examine their return values. A variable x has been preloaded for this exercise. Run the code below in the console. Pay close attention to the results to answer the question that follows.\n",
    "\n",
    "- Assign str(x) to a variable y1: y1 = str(x)\n",
    "- Assign print(x) to a variable y2: y2 = print(x)\n",
    "- Check the types of the variables x, y1, and y2.\n",
    "\n",
    "What are the types of x, y1, and y2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89\n"
     ]
    }
   ],
   "source": [
    "x = 4.89\n",
    "y1 = str(x)\n",
    "y2 = print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(float, str, NoneType)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), type(y1),type(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- They are all str types.\n",
    "- x is a float, y1 is an float, and y2 is a str.\n",
    "- x is a float, y1 is a str, and y2 is a NoneType.\n",
    "- They are all NoneType types.\n",
    "\n",
    "Correct! It is important to remember that assigning a variable y2 to a function that prints a value but does not return a value will result in that variable y2 being of type NoneType."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Write a simple function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last video, Hugo described the basics of how to define a function. You will now write your own function!\n",
    "\n",
    "Define a function, shout(), which simply prints out a string with three exclamation marks ‘!!!’ at the end. The code for the square() function that we wrote earlier is found below. You can use it as a pattern to define shout()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square():\n",
    "    new_value = 4 ** 2\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function body is indented 4 spaces already for you. Function bodies need to be indented by a consistent number of spaces and the choice of 4 is common.\n",
    "\n",
    "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the Python for Data Science Cheat Sheet and keep it handy!\n",
    "\n",
    "- Complete the function header by adding the appropriate function name, shout.\n",
    "- In the function body, concatenate the string, ‘congratulations’ with another string, ‘!!!’. Assign the result to shout_word.\n",
    "- Print the value of shout_word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# Definition the function shout\n",
    "def shout():\n",
    "    \"\"\"Print a string with three exclamation marks\"\"\"\n",
    "    # Concatenate the string: shout_word\n",
    "    shout_word = 'congratulations' + '!!!'\n",
    "    \n",
    "    # Print shout_word\n",
    "    print(shout_word)\n",
    "# Call shout\n",
    "shout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Single-parameter functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully defined and called your own function! That’s pretty cool.\n",
    "\n",
    "In the previous exercise, you defined and called the function shout(), which printed out a string concatenated with ‘!!!’. You will now update shout() by adding a parameter so that it can accept and process any string argument passed to it. Also note that shout(word), the part of the header that specifies the function name and parameter(s), is known as the signature of the function. You may encounter this term in the wild!\n",
    "\n",
    "- Complete the function header by adding the parameter name, word.\n",
    "- Assign the result of concatenating word with ‘!!!’ to shout_word.\n",
    "- Print the value of shout_word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout with the parameter, word\n",
    "def shout(word):\n",
    "    \"\"\"Print a string with three exclamation marks\"\"\"\n",
    "    # Concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "    \n",
    "    # Print shout_word\n",
    "    print(shout_word)\n",
    "shout('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 Functions that return single values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re getting very good at this! Try your hand at another modification to the shout() function so that it now returns a single value instead of printing within the function. Recall that the return keyword lets you return values from functions. Parts of the function shout(), which you wrote earlier, are shown. Returning values is generally more desirable than printing them out because, as you saw earlier, a print() call assigned to a variable has type NoneType.\n",
    "\n",
    "- In the function body, concatenate the string in word with ‘!!!’ and assign to shout_word.\n",
    "- Replace the print() statement with the appropriate return statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrutulations!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout with the parameter, word\n",
    "def shout(word):\n",
    "    \"\"\"Return a stirng with three exclamation marks\"\"\"\n",
    "    # Concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "    \n",
    "    # Replace print with return\n",
    "    return shout_word\n",
    "yell = shout('congrutulations')\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Here it made sense to assign the output of shout(‘congratulations’) to a variable yell because the function shout actually returns a value, it does not merely print one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multiple parameters and return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Functions with multiple parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugo discussed the use of multiple parameters in defining functions in the last lecture. You are now going to use what you’ve learned to modify the shout() function further. Here, you will modify shout() to accept two arguments. Parts of the function shout(), which you wrote earlier, are shown.\n",
    "\n",
    "- Modify the function header such that it accepts two parameters, word1 and word2, in that order.\n",
    "- Concatenate each of word1 and word2 with ‘!!!’ and assign to shout1 and shout2, respectively.\n",
    "- Concatenate shout1 and shout2 together, in that order, and assign to new_shout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulation!!! you!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout with parameters word1 and word2\n",
    "def shout(word1, word2):\n",
    "    \"\"\"Concatenate strings with three exclamation marks\"\"\"\n",
    "    shout1 = word1 + '!!!'\n",
    "    \n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + '!!!'\n",
    "    \n",
    "    # Concatenate shout1 with shout2: new_shout\n",
    "    new_shout = shout1 + shout2\n",
    "    \n",
    "    # Return new_shout\n",
    "    return new_shout\n",
    "\n",
    "# Pass ;congratulations' and 'you' to chout: yell\n",
    "yell = shout('congratulation', ' you')\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 A brief introduction to tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alongside learning about functions, you’ve also learned about tuples! Here, you will practice what you’ve learned about tuples: how to construct, unpack, and access tuple elements. Recall how Hugo unpacked the tuple even_nums in the video:\n",
    "\n",
    "a, b, c = even_nums\n",
    "\n",
    "A three-element tuple named nums has been preloaded for this exercise. Before completing the script, perform the following:\n",
    "\n",
    "- Print out the value of nums in the IPython shell. Note the elements in the tuple.\n",
    "- In the IPython shell, try to change the first element of nums to the value 2 by doing an assignment: nums[0] = 2. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = (3,4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unpack nums to the variables num1, num2, and num3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack nums into num1, num2, and num3\n",
    "num1, num2, num3 = nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct a new tuple, even_nums composed of the same elements in nums, but with the 1st element replaced with the value, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct even_nums\n",
    "even_nums = (2, num2, num3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Functions that return multiple values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you constructed tuples, assigned tuples to variables, and unpacked tuples. Here you will return multiple values from a function using tuples. Let’s now update our shout() function to return multiple values. Instead of returning just one string, we will return two strings with the string !!! concatenated to each.\n",
    "\n",
    "Note that the return statement return x, y has the same result as return (x, y): the former actually packs x and y into a tuple under the hood!\n",
    "\n",
    "- Modify the function header such that the function name is now shout_all, and it accepts two parameters, word1 and word2, in that order.\n",
    "- Concatenate the string ‘!!!’ to each of word1 and word2 and assign to shout1 and shout2, respectively.\n",
    "- Construct a tuple shout_words, composed of shout1 and shout2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n",
      "you!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout_all with parameters word1 and word2\n",
    "def shout_all(word1, word2):\n",
    "    \"\"\"Return a tuple of strings\"\"\"\n",
    "    # Concatenate word1 with '!!!': shout1\n",
    "    shout1 = word1 + '!!!'\n",
    "    \n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + '!!!'\n",
    "    \n",
    "    # Construct a tuple with shout1 and shout2: shout_words\n",
    "    shout_words = (shout1, shout2)\n",
    "    \n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Pass 'congratulations' and 'you' to shout_all(): yell1, yell2\n",
    "yell1, yell2 = shout_all('congratulations', 'you')\n",
    "\n",
    "# Print yell1 and yell2\n",
    "print(yell1)\n",
    "print(yell2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Bringing it all together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3.1 Bringing it all together (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve got your first taste of writing your own functions in the previous exercises. You’ve learned how to add parameters to your own function definitions, return a value or multiple values with tuples, and how to call the functions you’ve defined.\n",
    "\n",
    "In this and the following exercise, you will bring together all these concepts and apply them to a simple data science problem. You will load a dataset and develop functionalities to extract simple insights from the data.\n",
    "\n",
    "For this exercise, your goal is to recall how to load a dataset into a DataFrame. The dataset contains Twitter data and you will iterate over entries in a column to build a dictionary in which the keys are the names of languages and the values are the number of tweets in the given language. The file tweets.csv is available in your current directory.\n",
    "\n",
    "Be aware that this is real data from Twitter and as such there is always a risk that it may contain profanity or other offensive content (in this exercise, and any following exercises that also use real Twitter data).\n",
    "\n",
    "- Import the pandas package with the alias pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the file ‘tweets.csv’ using the pandas function read_csv(). Assign the resulting DataFrame to df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401759387648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>1459294817758</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401977319424</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>1459294817810</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402426236928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
       "      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n",
       "      <td>1459294817917</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402367561730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Your an idiot she shouldn't have tried to grab...</td>\n",
       "      <td>1459294817903</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402149416960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': 'The anti-America...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n",
       "      <td>1459294817851</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': -18000, 'profile_image_url_http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "3           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "4           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "3  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "4  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "3      False          low  NaN  714960402367561730  ...      7.149239e+17   \n",
       "4      False          low  NaN  714960402149416960  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "3         7.149239e+17              0      False   \n",
       "4                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'retweeted': False, 'text': 'The anti-America...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...  1459294817917     False   \n",
       "3  Your an idiot she shouldn't have tried to grab...  1459294817903     False   \n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...  1459294817851     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "3  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "4  {'utc_offset': -18000, 'profile_image_url_http...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Twitter data as DataFrame: df\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the for loop by iterating over col, the ‘lang’ column in the DataFrame df.\n",
    "- Complete the bodies of the if-else statements in the for loop: if the key is in the dictionary langs_count, add 1 to the value corresponding to this key in the dictionary, else add the key to langs_count and set the corresponding value to 1. Use the loop variable entry in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary: langs_count\n",
    "langs_count = {}\n",
    "\n",
    "# Extract column from Dataframe: col\n",
    "col = df['lang']\n",
    "\n",
    "# Iterate over lang column in DataFrame\n",
    "for entry in col:\n",
    "    \n",
    "    # If the language is in langs_count, add 1\n",
    "    if entry in langs_count.keys():\n",
    "        langs_count[entry] += 1\n",
    "    # Else add the language to langs_count, set the value to 1\n",
    "    else:\n",
    "        langs_count[entry] = 1\n",
    "\n",
    "# Print to populated dictionary\n",
    "print(langs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3.2 Bringing it all together (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You’ve now defined the functionality for iterating over entries in a column and building a dictionary with keys the names of languages and values the number of tweets in the given language.\n",
    "\n",
    "In this exercise, you will define a function with the functionality you developed in the previous exercise, return the resulting dictionary from within the function, and call the function with the appropriate arguments.\n",
    "\n",
    "For your convenience, the pandas package has been imported as pd and the ‘tweets.csv’ file has been imported into the tweets_df variable.\n",
    "\n",
    "- Define the function count_entries(), which has two parameters. The first parameter is df for the DataFrame and the second is col_name for the column name.\n",
    "- Complete the bodies of the if-else statements in the for loop: if the key is in the dictionary langs_count, add 1 to its current value, else add the key to langs_count and set its value to 1. Use the loop variable entry in your code.\n",
    "- Return the langs_count dictionary from inside the count_entries() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries():\n",
    "def count_entries(df, col_name):\n",
    "    \"\"\"Return a dictionary with counts of occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: langs_count\n",
    "    langs_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over lang column in DataFrame\n",
    "    for entry in col:\n",
    "        \n",
    "        # If the language is in langs_count, add 1\n",
    "        if entry in langs_count.keys():\n",
    "            langs_count[entry] += 1\n",
    "        # Else add the language to langs_count, set the value to 1\n",
    "        else:\n",
    "            langs_count[entry] = 1\n",
    "    \n",
    "    # Return the langs_count dictionary\n",
    "    return langs_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call the count_entries() function by passing to it tweets_df and the name of the column, ‘lang’. Assign the result of the call to the variable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/tweets.csv')\n",
    "\n",
    "# Call count_entries(): result\n",
    "result = count_entries(tweets_df, 'lang')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 Default arguments, variable-length arguments and scope**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you’ll learn to write functions with default arguments so that the user doesn’t always need to specify them, and variable-length arguments so they can pass an arbitrary number of arguments on to your functions. You’ll also learn about the essential concept of scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Scope and user-defined functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1.1 Pop quiz on understanding scope**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will practice what you’ve learned about scope in functions. The variable num has been predefined as 5, alongside the following function definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1():\n",
    "    num = 3\n",
    "    print(num)\n",
    "\n",
    "def func2():\n",
    "    global num\n",
    "    double_num = num * 2\n",
    "    num = 6\n",
    "    print(double_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try calling func1() and func2() in the shell, then answer the following questions:\n",
    "\n",
    "- What are the values printed out when you call func1() and func2()?\n",
    "- What is the value of num in the global scope after calling func1() and func2()?\n",
    "- func1() prints out 3, func2() prints out 6, and the value of num in the global scope is 3.\n",
    "- func1() prints out 3, func2() prints out 3, and the value of num in the global scope is 3.\n",
    "- func1() prints out 3, func2() prints out 10, and the value of num in the global scope is 10.\n",
    "- func1() prints out 3, func2() prints out 10, and the value of num in the global scope is 6.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1.2 The keyword global**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s work more on your mastery of scope. In this exercise, you will use the keyword global within a function to alter the value of a variable defined in the global scope.\n",
    "\n",
    "- Use the keyword global to alter the object team in the global scope.\n",
    "- Change the value of team in the global scope to the string “justice league”. Assign the result to team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "justice league\n",
      "justice league\n"
     ]
    }
   ],
   "source": [
    "# Create a string: team\n",
    "team = \"teen titans\"\n",
    "\n",
    "# Define change_team()\n",
    "def change_team():\n",
    "    \"\"\"Change the value of the global variable team.\"\"\"\n",
    "    \n",
    "    # Use team in global scope\n",
    "    global team\n",
    "    \n",
    "    # Change the value of team in global: team\n",
    "    team = \"justice league\"\n",
    "    print(team)\n",
    "    \n",
    "# Call change_team()\n",
    "change_team()\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1.3 Python’s built-in scope**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you’re going to check out Python’s built-in scope, which is really just a built-in module called builtins. However, to query builtins, you’ll need to import builtins ‘because the name builtins is not itself built in…No, I’m serious!’ (Learning Python, 5th edition, Mark Lutz). After executing import builtins in the IPython Shell, execute dir(builtins) to print a list of all the names in the module builtins. Have a look and you’ll see a bunch of names that you’ll recognize! Which of the following names is NOT in the module builtins?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ‘sum’\n",
    "- ‘range’\n",
    "- ‘array’\n",
    "- ‘tuple’\n",
    "\n",
    "You got it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Nested functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2.1 Nested Functions I**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve learned in the last video about nesting functions within functions. One reason why you’d like to do this is to avoid writing out the same computations within functions repeatedly. There’s nothing new about defining nested functions: you simply define it as you would a regular function with def and embed it inside another function!\n",
    "\n",
    "In this exercise, inside a function three_shouts(), you will define a nested function inner() that concatenates a string object with !!!. three_shouts() then returns a tuple of three elements, each a string concatenated with !!! using inner(). Go for it!\n",
    "\n",
    "- Complete the function header of the nested function with the function name inner() and a single parameter word.\n",
    "- Complete the return value: each element of the tuple should be a call to inner(), passing in the parameters from three_shouts() as arguments to each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a!!!', 'b!!!', 'c!!!')\n"
     ]
    }
   ],
   "source": [
    "# Define three_shouts\n",
    "def three_shouts(word1, word2, word3):\n",
    "    \"\"\"Returns a tuple of strings concatenate with '!!!'.\"\"\"\n",
    "    \n",
    "    # Define inner\n",
    "    def inner(word):\n",
    "        \"\"\"Returns a strings concatenated with '!!!'.\"\"\"\n",
    "        return word + '!!!'\n",
    "    \n",
    "    # Return a tuple of strings\n",
    "    return (inner(word1), inner(word2), inner(word3))\n",
    "\n",
    "# Call three_shouts() and print\n",
    "print(three_shouts('a','b','c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.2 Nested Functions II**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job, you’ve just nested a function within another function. One other pretty cool reason for nesting functions is the idea of a closure. This means that the nested or inner function remembers the state of its enclosing scope when called. Thus, anything defined locally in the enclosing scope is available to the inner function even when the outer function has finished execution.\n",
    "\n",
    "Let’s move forward then! In this exercise, you will complete the definition of the inner function inner_echo() and then call echo() a couple of times, each with a different argument. Complete the exercise and see what the output will be!\n",
    "\n",
    "- Complete the function header of the inner function with the function name inner_echo() and a single parameter word1.\n",
    "- Complete the function echo() so that it returns inner_echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define echo\n",
    "def echo(n):\n",
    "    \"\"\"Return the inner_echo function.\"\"\"\n",
    "    \n",
    "    # Define inner_echo\n",
    "    def inner_echo(word1):\n",
    "        \"\"\"Concatenate n copies of word1.\"\"\"\n",
    "        echo_word = word1 * n\n",
    "        return echo_word\n",
    "\n",
    "    # Return inner_echo\n",
    "    return inner_echo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have called echo(), passing 2 as an argument, and assigned the resulting function to twice. Your job is to call echo(), passing 3 as an argument. Assign the resulting function to thrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call echo: twice\n",
    "twice = echo(2)\n",
    "\n",
    "# Call echo: thrice\n",
    "thrice = echo(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hit Submit to call twice() and thrice() and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello hellohellohello\n"
     ]
    }
   ],
   "source": [
    "# Call twice() and thrice() then print\n",
    "print(twice('hello'), thrice('hello'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2.3 The keyword nonlocal and nested functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s once again work further on your mastery of scope! In this exercise, you will use the keyword nonlocal within a nested function to alter the value of a variable defined in the enclosing scope.\n",
    "\n",
    "- Assign to echo_word the string word, concatenated with itself.\n",
    "- Use the keyword nonlocal to alter the value of echo_word in the enclosing scope.\n",
    "- Alter echo_word to echo_word concatenated with ‘!!!’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define echo_shout()\n",
    "def echo_shout(word):\n",
    "    \"\"\"Change the value of a nonlocal variable\"\"\"\n",
    "    \n",
    "    # Concatenate word with itself: echo_word\n",
    "    echo_word = word * 2\n",
    "    \n",
    "    print(echo_word)\n",
    "    \n",
    "    # Define inner function shout()\n",
    "    def shout():\n",
    "        \"\"\"Alter a variable in the enclosing scope\"\"\"\n",
    "        \n",
    "        # Use echo_word in nonlocal scope\n",
    "        nonlocal echo_word\n",
    "        \n",
    "        # Change echo_word to echo_word concatenated with '!!!'\n",
    "        echo_word = echo_word + '!!!'\n",
    "    \n",
    "    # Call function shout()\n",
    "    shout()\n",
    "    print(echo_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello\n",
      "hellohello!!!\n"
     ]
    }
   ],
   "source": [
    "# Call function echo_shout() with argument 'hello'\n",
    "echo_shout('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Default and flexible arguments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3.1 Functions with one default argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter, you’ve learned to define functions with more than one parameter and then calling those functions by passing the required number of arguments. In the last video, Hugo built on this idea by showing you how to define functions with default arguments. You will practice that skill in this exercise by writing a function that uses a default argument and then calling the function a couple of times.\n",
    "\n",
    "- Complete the function header with the function name shout_echo. It accepts an argument word1 and a default argument echo with default value 1, in that order.\n",
    "- Use the * operator to concatenate echo copies of word1. Assign the result to echo_word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three exclamation marks at the\n",
    "    end of the string.\"\"\"\n",
    "    \n",
    "    # Concatenate echo copies of word1 using *:echo_word\n",
    "    echo_word = word1 * echo\n",
    "    \n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "    \n",
    "    # Return shout_word\n",
    "    return shout_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call shout_echo() with just the string, “Hey”. Assign the result to no_echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_echo = shout_echo(\"Hey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call shout_echo() with the string “Hey” and the value 5 for the default argument, echo. Assign the result to with_echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey!!!\n"
     ]
    }
   ],
   "source": [
    "# Call shout_echo() with \"Hey\" and echo=5: with_echo\n",
    "with_echo = shout_echo(\"Hey\", echo=5)\n",
    "\n",
    "print(no_echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeyHeyHeyHeyHey!!!\n"
     ]
    }
   ],
   "source": [
    "print(with_echo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3.2 Functions with multiple default arguments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve now defined a function that uses a default argument - don’t stop there just yet! You will now try your hand at defining a function with more than one default argument and then calling this function in various ways.\n",
    "\n",
    "After defining the function, you will call it by supplying values to all the default arguments of the function. Additionally, you will call the function by not passing a value to one of the default arguments - see how that changes the output of your function!\n",
    "\n",
    "- Complete the function header with the function name shout_echo. It accepts an argument word1, a default argument echo with default value 1 and a default argument intense with default value False, in that order.\n",
    "- In the body of the if statement, make the string object echo_word upper case by applying the method .upper() on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1, intense=False):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the strings.\"\"\"\n",
    "    \n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "    \n",
    "    # Make echo_word uppercase if intense is True\n",
    "    if intense is True:\n",
    "        # Make uppercase and concatenate '!!!': echo_word_new\n",
    "        echo_word_new = echo_word.upper() + '!!!'\n",
    "    else:\n",
    "        # Concatenate '!!!' to echo_word: echo_word_new\n",
    "        echo_word_new = echo_word + '!!!'\n",
    "    # Return echo_word_new\n",
    "    return echo_word_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call shout_echo() with the string, “Hey”, the value 5 for echo and the value True for intense. Assign the result to with_big_echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call shout_echo() with \"Hey\", echo = 5 and intense=True: with_big_echo\n",
    "with_big_echo = shout_echo(\"Hey\", echo=5, intense=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call shout_echo() with the string “Hey” and the value True for intense. Assign the result to big_no_echo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEYHEYHEYHEYHEY!!!\n",
      "HEY!!!\n"
     ]
    }
   ],
   "source": [
    "# Call shout_echo() with \"Hey\" and intense = True: big_no_echo\n",
    "big_no_echo = shout_echo(\"Hey\", intense=True)\n",
    "\n",
    "print(with_big_echo)\n",
    "print(big_no_echo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __2.3.3 Functions with variable-length arguments (*args)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flexible arguments enable you to pass a variable number of arguments to a function. In this exercise, you will practice defining a function that accepts a variable number of string arguments.\n",
    "\n",
    "The function you will define is gibberish() which can accept a variable number of string values. Its return value is a single string composed of all the string arguments concatenated together in the order they were passed to the function call. You will call the function with a single string argument and see how the output changes with another call using more than one string argument. Recall from the previous video that, within the function definition, args is a tuple.\n",
    "\n",
    "- Complete the function header with the function name gibberish. It accepts a single flexible argument *args.\n",
    "- Initialize a variable hodgepodge to an empty string.\n",
    "- Return the variable hodgepodge at the end of the function body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gibberish\n",
    "def gibberish(*args):\n",
    "    \"\"\"Concatenate strings in *args together.\"\"\"\n",
    "    \n",
    "    # Initialize an empty string: hodgepodge\n",
    "    hodgepodge = ''\n",
    "    \n",
    "    # Concatenate the strings in args\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "    \n",
    "    # Return hodgepodge\n",
    "    return hodgepodge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call gibberish() with the single string, “luke”. Assign the result to one_word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call gibberish() with one string: one_word\n",
    "one_word = gibberish(\"luke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hit the Submit button to call gibberish() with multiple arguments and to print the value to the Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luke\n",
      "luke leisa han obi darth\n"
     ]
    }
   ],
   "source": [
    "# Call gibberish() with five strings: many_words\n",
    "many_words = gibberish(\"luke\", \" leisa\", \" han\", \" obi\", \" darth\")\n",
    "\n",
    "print(one_word)\n",
    "print(many_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __2.3.4 Functions with variable-length keyword arguments (**kwargs)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s push further on what you’ve learned about flexible arguments - you’ve used *args, you’re now going to use **kwargs! What makes **kwargs different is that it allows you to pass a variable number of keyword arguments to functions. Recall from the previous video that, within the function definition, kwargs is a dictionary.\n",
    "\n",
    "To understand this idea better, you’re going to use **kwargs in this exercise to define a function that accepts a variable number of keyword arguments. The function simulates a simple status report system that prints out the status of a character in a movie.\n",
    "\n",
    "- Complete the function header with the function name report_status. It accepts a single flexible argument **kwargs.\n",
    "- Iterate over the key-value pairs of kwargs to print out the keys and values, separated by a colon ‘:’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define report_status:\n",
    "def report_status(**kwargs):\n",
    "    \"\"\"Print out the status of a movie character.\"\"\"\n",
    "    \n",
    "    print(\"\\nBEGIN: REPORT\\n\")\n",
    "    \n",
    "    # Iterate over the key-value pairs of kwargs\n",
    "    for key, value in kwargs.items():\n",
    "        # Print out the keys and values, separated by a colon ':'\n",
    "        print(key + \": \" + value)\n",
    "    print(\"\\nEND REPORT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first call to report_status(), pass the following keyword-value pairs: name=“luke”, affiliation=“jedi” and status=“missing”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: luke\n",
      "affiliation: jedi\n",
      "status: missing\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "report_status(name=\"luke\", affiliation=\"jedi\", status=\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the second call to report_status(), pass the following keyword-value pairs: name=“anakin”, affiliation=“sith lord” and status=“deceased”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: anakin\n",
      "affiliation: sith lord\n",
      "status: descresed\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "# Second call to report_status()\n",
    "report_status(name=\"anakin\", affiliation=\"sith lord\", status=\"descresed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Bringing it all together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.4.1 Bringing it all together (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the Bringing it all together exercise in the previous chapter where you did a simple Twitter analysis by developing a function that counts how many tweets are in certain languages. The output of your function was a dictionary that had the language as the keys and the counts of tweets in that language as the value.\n",
    "\n",
    "In this exercise, we will generalize the Twitter language analysis that you did in the previous chapter. You will do that by including a default argument that takes a column name.\n",
    "\n",
    "For your convenience, pandas has been imported as pd and the ‘tweets.csv’ file has been imported into the DataFrame tweets_df. Parts of the code from your previous work are also provided.\n",
    "\n",
    "- Complete the function header by supplying the parameter for a DataFrame df and the parameter col_name with a default value of ‘lang’ for the DataFrame column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "        \n",
    "        # If entry is in cols_count, add 1:\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "        \n",
    "        # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "    \n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call count_entries() by passing the tweets_df DataFrame and the column name ‘lang’. Assign the result to result1. Note that since ‘lang’ is the default value of the col_name parameter, you don’t have to specify it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, col_name='lang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call count_entries() by passing the tweets_df DataFrame and the column name ‘source’. Assign the result to result2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, col_name='source')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.4.2 Bringing it all together (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, you’ve just generalized your Twitter language analysis that you did in the previous chapter to include a default argument for the column name. You’re now going to generalize this function one step further by allowing the user to pass it a flexible argument, that is, in this case, as many column names as the user would like!\n",
    "\n",
    "Once again, for your convenience, pandas has been imported as pd and the ‘tweets.csv’ file has been imported into the DataFrame tweets_df. Parts of the code from your previous work are also provided.\n",
    "\n",
    "- Complete the function header by supplying the parameter for the DataFrame df and the flexible argument *args.\n",
    "- Complete the for loop within the function definition so that the loop occurs over the tuple args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, *args):\n",
    "    \"\"\"Return a dictionary with counts of occurences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Iterate over column names in args\n",
    "    for col_name in args:\n",
    "        \n",
    "        # Extract column from DataFrame: col    \n",
    "        col = df[col_name]\n",
    "        \n",
    "        # Iterate over the column in DataFrame \n",
    "        for entry in col:\n",
    "            \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            \n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "    \n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call count_entries() by passing the tweets_df DataFrame and the column name ‘lang’. Assign the result to result1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call count_entries() by passing the tweets_df DataFrame and the column names ‘lang’ and ‘source’. Assign the result to result2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "{'en': 97, 'et': 1, 'und': 2, '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'lang', 'source')\n",
    "\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 Lambda functions and error-handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn about lambda functions, which allow you to write functions quickly and on the fly. You’ll also practice handling errors in your functions, which is an essential skill. Then, apply your new skills to answer data science questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Lambda functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1.1 Pop quiz on lambda functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will practice writing a simple lambda function and calling this function. Recall what you know about lambda functions and answer the following questions:\n",
    "\n",
    "- How would you write a lambda function add_bangs that adds three exclamation points ‘!!!’ to the end of a string a?\n",
    "- How would you call add_bangs with the argument ‘hello’?\n",
    "\n",
    "You may use the IPython shell to test your code.\n",
    "\n",
    "- The lambda function definition is: add_bangs = (a + ‘!!!’), and the function call is: add_bangs(‘hello’).\n",
    "- The lambda function definition is: add_bangs = (lambda a: a + ‘!!!’), and the function call is: add_bangs(‘hello’).\n",
    "- The lambda function definition is: (lambda a: a + ‘!!!’) = add_bangs, and the function call is: add_bangs(‘hello’).\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1.2 Writing a lambda function you already know**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some function definitions are simple enough that they can be converted to a lambda function. By doing this, you write less lines of code, which is pretty awesome and will come in handy, especially when you’re writing and maintaining big programs. In this exercise, you will use what you know about lambda functions to convert a function that does a simple task into a lambda function. Take a look at this function definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_word(word1, echo):\n",
    "    \"\"\"Concatenate echo copies of word1.\"\"\"\n",
    "    words = word1 * echo\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function echo_word takes 2 parameters: a string value, word1 and an integer value, echo. It returns a string that is a concatenation of echo copies of word1. Your task is to convert this simple function into a lambda function.\n",
    "\n",
    "- Define the lambda function echo_word using the variables word1 and echo. Replicate what the original function definition for echo_word() does above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define echo_word as a lambda function: echo_word\n",
    "echo_word = (lambda word1, echo: word1 * echo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call echo_word() with the string argument ‘hey’ and the value 5, in that order. Assign the call to result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey hey hey hey hey \n"
     ]
    }
   ],
   "source": [
    "# Call echo_word: result\n",
    "result = echo_word('hey ',5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1.3 Map() and lambda functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you’ve used lambda functions to write short, simple functions as well as to redefine functions with simple functionality. The best use case for lambda functions, however, are for when you want these simple functionalities to be anonymously embedded within larger expressions. What that means is that the functionality is not stored in the environment, unlike a function defined with def. To understand this idea better, you will use a lambda function in the context of the map() function.\n",
    "\n",
    "Recall from the video that map() applies a function over an object, such as a list. Here, you can use lambda functions to define the function that map() will use to process the object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "cums = [2,4,6,8,10]\n",
    "\n",
    "result = map(lambda a: a ** 2, nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that a lambda function, which raises a value a to the power of 2, is passed to map() alongside a list of numbers, nums. The map object that results from the call to map() is stored in result. You will now practice the use of lambda functions with map(). For this exercise, you will map the functionality of the add_bangs() function you defined in previous exercises over a list of strings.\n",
    "\n",
    "- In the map() call, pass a lambda function that concatenates the string ‘!!!’ to a string item; also pass the list of strings, spells. Assign the resulting map object to shout_spells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings: spells\n",
    "spells = ['protego', 'accio', 'expecto patronum', 'legilimens']\n",
    "\n",
    "# Use map() to apply a lambda function over spells: shout_spells\n",
    "shout_spells = map(lambda item: item + '!!!', spells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert shout_spells to a list and print out the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protego!!!', 'accio!!!', 'expecto patronum!!!', 'legilimens!!!']\n"
     ]
    }
   ],
   "source": [
    "# Convert shout_spells to a list: shout_spells_list\n",
    "shout_spells_list = list(shout_spells)\n",
    "\n",
    "print(shout_spells_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1.4 Filter() and lambda functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you used lambda functions to anonymously embed an operation within map(). You will practice this again in this exercise by using a lambda function with filter(), which may be new to you! The function filter() offers a way to filter out elements from a list that don’t satisfy certain criteria.\n",
    "\n",
    "Your goal in this exercise is to use filter() to create, from an input list of strings, a new list that contains only strings that have more than 6 characters.\n",
    "\n",
    "- In the filter() call, pass a lambda function and the list of strings, fellowship. The lambda function should check if the number of characters in a string member is greater than 6; use the len() function to do this. Assign the resulting filter object to result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry','pippin','aragorn','boromir','legolas','gimli','gandalf']\n",
    "\n",
    "# Use filter() to apply a lambda function over fellowship: result\n",
    "result = filter(lambda member: len(member) > 6, fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert result to a list and print out the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'boromir', 'legolas', 'gandalf']\n"
     ]
    }
   ],
   "source": [
    "# Convert result to a list: result_list\n",
    "result_list = list(result)\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1.5 Reduce() and lambda functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re getting very good at using lambda functions! Here’s one more function to add to your repertoire of skills. The reduce() function is useful for performing some computation on a list and, unlike map() and filter(), returns a single value as a result. To use reduce(), you must import it from the functools module.\n",
    "\n",
    "Remember gibberish() from a few exercises back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gibberish\n",
    "def gibberish(*args):\n",
    "    \"\"\"Concatenate strings in *args together.\"\"\"\n",
    "    hodgepodge = ''\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "    return hodgepodge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gibberish() simply takes a list of strings as an argument and returns, as a single-value result, the concatenation of all of these strings. In this exercise, you will replicate this functionality by using reduce() and a lambda function that concatenates strings together.\n",
    "\n",
    "- Import the reduce function from the functools module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reduce from functools\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the reduce() call, pass a lambda function that takes two string arguments item1 and item2 and concatenates them; also pass the list of strings, stark. Assign the result to result. The first argument to reduce() should be the lambda function and the second argument is the list stark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robbsansaaryabrandonrickon\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: stark\n",
    "stark = ['robb', 'sansa', 'arya','brandon','rickon']\n",
    "\n",
    "# Use reduce() to apply a lambda fuction over stark: result\n",
    "result = reduce(lambda item1, item2: item1 + item2, stark)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Introduction to error handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.1 Pop quiz about errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, Hugo talked about how errors happen when functions are supplied arguments that they are unable to work with. In this exercise, you will identify which function call raises an error and what type of error is raised.\n",
    "\n",
    "Take a look at the following function calls to len():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len('There is a beast in every man and it stirs when you put a sword in his hand.')\n",
    "\n",
    "# len(['robb', 'sansa', 'arya', 'eddard', 'jon'])\n",
    "\n",
    "# len(525600)\n",
    "\n",
    "# len(('jaime', 'cersei', 'tywin', 'tyrion', 'joffrey'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the function calls raises an error and what type of error is raised?\n",
    "- The call len(‘There is a beast in every man and it stirs when you put a sword in his hand.’) raises a TypeError.\n",
    "- The call len([‘robb’, ‘sansa’, ‘arya’, ‘eddard’, ‘jon’]) raises an IndexError.\n",
    "- The call len(525600) raises a TypeError.\n",
    "- The call len((‘jaime’, ‘cersei’, ‘tywin’, ‘tyrion’, ‘joffrey’)) raises a NameError.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.2 Error handling with try-except**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good practice in writing your own functions is also anticipating the ways in which other people (or yourself, if you accidentally misuse your own function) might use the function you defined.\n",
    "\n",
    "As in the previous exercise, you saw that the len() function is able to handle input arguments such as strings, lists, and tuples, but not int type ones and raises an appropriate error and error message when it encounters invalid input arguments. One way of doing this is through exception handling with the try-except block.\n",
    "\n",
    "In this exercise, you will define a function as well as use a try-except block for handling cases when incorrect input arguments are passed to the function.\n",
    "\n",
    "Recall the shout_echo() function you defined in previous exercises; parts of the function definition are provided in the sample code. Your goal is to complete the exception handling code in the function definition and provide an appropriate error message when raising an error.\n",
    "\n",
    "- Initialize the variables echo_word and shout_words to empty strings.\n",
    "- Add the keywords try and except in the appropriate locations for the exception handling block.\n",
    "- Use the * operator to concatenate echo copies of word1. Assign the result to echo_word.\n",
    "- Concatenate the string ‘!!!’ to echo_word. Assign the result to shout_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1 must be a string and echo must be an integer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "    \n",
    "    # Initialize empty strings: echo_word, shout_words\n",
    "    echo_word = ' '\n",
    "    shout_words = ' '\n",
    "    \n",
    "    # Add exception handling with try-except\n",
    "    try:\n",
    "        # Concatenate echo copies of word1 using *: echo_word\n",
    "        echo_word = word1 * echo\n",
    "        \n",
    "        # Concatenate '!!!' to echo_word: shout_words\n",
    "        shout_words = echo_word + '!!!'\n",
    "        \n",
    "    except:\n",
    "        print(\"word1 must be a string and echo must be an integer.\")\n",
    "        \n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=\"accelerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.3 Error handling by raising an error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to raise an error is by using raise. In this exercise, you will add a raise statement to the shout_echo() function you defined before to raise an error message when the value supplied by the user to the echo argument is less than 0.\n",
    "\n",
    "The call to shout_echo() uses valid argument values. To test and see how the raise statement works, simply change the value for the echo argument to a negative value. Don’t forget to change it back to valid values to move on to the next exercise!\n",
    "\n",
    "- Complete the if statement by checking if the value of echo is less than 0.\n",
    "- In the body of the if statement, add a raise statement that raises a ValueError with message ‘echo must be greater than or equal to 0’ when the value supplied by the user to echo is less than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'particleparticleparticleparticleparticle!!!'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "    \n",
    "    # Raise an error with raise\n",
    "    if echo < 0:\n",
    "        raise ValueError('echo must be greater than or equal to 0')\n",
    "    \n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "    \n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "    \n",
    "    # Return shout_word\n",
    "    return shout_word\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Bringing it all together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.1 Bringing it all together (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is awesome! You have now learned how to write anonymous functions using lambda, how to pass lambda functions as arguments to other functions such as map(), filter(), and reduce(), as well as how to write errors and output custom error messages within your functions. You will now put together these learnings to good use by working with a Twitter dataset. Before practicing your new error handling skills; in this exercise, you will write a lambda function and use filter() to select retweets, that is, tweets that begin with the string ‘RT’.\n",
    "\n",
    "To help you accomplish this, the Twitter data has been imported into the DataFrame, tweets_df. Go for it!\n",
    "\n",
    "- In the filter() call, pass a lambda function and the sequence of tweets as strings, tweets_df[‘text’]. The lambda function should check if the first 2 characters in a tweet x are ‘RT’. Assign the resulting filter object to result. To get the first 2 characters in a tweet x, use x[0:2]. To check equality, use a Boolean filter with ==."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select retweets from the Twitter DataFrame: result\n",
    "result = filter(lambda x: x[0:2] == 'RT', tweets_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert result to a list and print out the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/…\n",
      "RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3\n",
      "RT @AlanLohner: The anti-American D.C. elites despise Trump for his America-first foreign policy. Trump threatens their gravy train. https:…\n",
      "RT @BIackPplTweets: Young Donald trump meets his neighbor  https://t.co/RFlu17Z1eE\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @HouseCracka: 29,000+ PEOPLE WATCHING TRUMP LIVE ON ONE STREAM!!!\n",
      "\n",
      "https://t.co/7QCFz9ehNe\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  https…\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/…\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  https…\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearly…\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET https…\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/…\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://…\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET https…\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://…\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearly…\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9N…\n",
      "RT @Norsu2: Nightmare WI poll for Ted Cruz has Kasich surging: Trump 29, Kasich 27, Cruz 25. https://t.co/lJsgbLYY1P #NeverTrump\n",
      "RT @thehill: WATCH: Protester pepper-sprayed point blank at Trump rally https://t.co/B5f65Al9ld https://t.co/skAfByXuQc\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9N…\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/…\n",
      "RT @DebbieStout5: Wow! Last I checked it was just 12 points &amp; that wasn't more than a day ago. Oh boy Trump ppl might want to rethink🤔 http…\n",
      "RT @tyleroakley: i'm a messy bitch, but at least i'm not voting for trump\n",
      "RT @vandives: Trump supporters r tired of justice NOT being served. There's no justice anymore. Hardworking Americans get screwed. That's n…\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNN…\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will n…\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNN…\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:…\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will n…\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:…\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation P…\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educat…\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation P…\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educat…\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @T…\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/…\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didn’t come out of nowhere.\" —Hillary\n",
      "https…\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @T…\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didn’t come out of nowhere.\" —Hillary\n",
      "https…\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/…\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating t…\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating t…\n",
      "RT @GlendaJazzey: Donald Trump’s Campaign Financing Dodge, @rrotunda https://t.co/L8flI4lswG via @VerdictJustia\n",
      "RT @TUSK81: LOUDER FOR THE PEOPLE IN THE BACK https://t.co/hlPVyNLXzx\n",
      "RT @loopzoop: Well...put it back https://t.co/8Yb7BDT5VM\n",
      "RT @claytoncubitt: Stop asking Bernie supporters if they’ll vote for Hillary against Trump. We got a plan to beat Trump already. Called Ber…\n",
      "RT @akaMaude13: Seriously can't make this up. What a joke. #NeverTrump  https://t.co/JkTx6mdRgC\n"
     ]
    }
   ],
   "source": [
    "# Create list from filter object result: res_list\n",
    "res_list = list(result)\n",
    "\n",
    "# Print all retweets in res_list:\n",
    "for tweet in res_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.2 Bringing it all together (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we make mistakes when calling functions - even ones you made yourself. But don’t fret! In this exercise, you will improve on your previous work with the count_entries() function in the last chapter by adding a try-except block to it. This will allow your function to provide a helpful message when the user calls your count_entries() function but provides a column name that isn’t in the DataFrame.\n",
    "\n",
    "Once again, for your convenience, pandas has been imported as pd and the ‘tweets.csv’ file has been imported into the DataFrame tweets_df. Parts of the code from your previous work are also provided.\n",
    "\n",
    "- Add a try block so that when the function is called with the correct arguments, it processes the DataFrame and returns a dictionary of results.\n",
    "- Add an except block so that when the function is called incorrectly, it displays the following error message: ‘The DataFrame does not have a’ + col_name + ’ column.’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Add try block\n",
    "    try:\n",
    "        # Extract column from DataFrame: col\n",
    "        col = df[col_name]\n",
    "        \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in col:\n",
    "            \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "        \n",
    "        # Return the cols_count dictionary\n",
    "        return cols_count\n",
    "    \n",
    "    # Add except block\n",
    "    except:\n",
    "        print('The DataFrame does not have a ' + col_name + ' column.')\n",
    "        \n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.3 Bringing it all together (3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you built on your function count_entries() to add a try-except block. This was so that users would get helpful messages when calling your count_entries() function and providing a column name that isn’t in the DataFrame. In this exercise, you’ll instead raise a ValueError in the case that the user provides a column name that isn’t in the DataFrame.\n",
    "\n",
    "Once again, for your convenience, pandas has been imported as pd and the ‘tweets.csv’ file has been imported into the DataFrame tweets_df. Parts of the code from your previous work are also provided.\n",
    "\n",
    "- If col_name is not a column in the DataFrame df, raise a ValueError ‘The DataFrame does not have a’ + col_name + ’ column.’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of occurences as value for each key.\"\"\"\n",
    "    \n",
    "    # Raise a ValueError if col_name is NOT in DataFrame\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError('The DataFrame does not have a ' + col_name + ' column.')\n",
    "    \n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "        \n",
    "        # If entry is in cols_count, add 1:\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "            # Else add the entry to cols_count, set the value to 1:\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "        \n",
    "        # Return the cols_count dictionary\n",
    "    return cols_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call your new function count_entries() to analyze the ‘lang’ column of tweets_df. Store the result in result1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print result1. This has been done for you, so hit ‘Submit Answer’ to check out the result. In the next exercise, you’ll see that it raises the necessary ValueErrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.4 Bringing it all together: testing your error handling skills**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have just written error handling into your count_entries() function so that, when the user passes the function a column (as 2nd argument) NOT contained in the DataFrame (1st argument), a ValueError is thrown. You’re now going to play with this function: it is loaded into pre-exercise code, as is the DataFrame tweets_df. Try calling count_entries(tweets_df, ‘lang’) to confirm that the function behaves as it should. Then call count_entries(tweets_df, ‘lang1’): what is the last line of the output?\n",
    "\n",
    "- ‘ValueError: The DataFrame does not have the requested column.’\n",
    "- ‘ValueError: The DataFrame does not have a lang1 column.’\n",
    "- ‘TypeError: The DataFrame does not have the requested column.’\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4 Using iterators in PythonLand**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll learn all about iterators and iterables, which you have already worked with when writing for loops. You’ll learn some handy functions that will allow you to effectively work with iterators. And you’ll finish the chapter with a use case that is pertinent to the world of data science and dealing with large amounts of data—in this case, data from Twitter that you will load in chunks using iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Introduction to iterators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1.1 Iterators vs. Iterables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s do a quick recall of what you’ve learned about iterables and iterators. Recall from the video that an iterable is an object that can return an iterator, while an iterator is an object that keeps state and produces the next value when you call next() on it. In this exercise, you will identify which object is an iterable and which is an iterator.\n",
    "\n",
    "The environment has been pre-loaded with the variables flash1 and flash2. Try printing out their values with print() and next() to figure out which is an iterable and which is an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash1 = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "flash2 = iter(flash1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both flash1 and flash2 are iterators.\n",
    "- Both flash1 and flash2 are iterables.\n",
    "- flash1 is an iterable and flash2 is an iterator.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.2 Iterating over iterables (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, you’re familiar with what iterables and iterators are! In this exercise, you will reinforce your knowledge about these by iterating over and printing from iterables and iterators.\n",
    "\n",
    "You are provided with a list of strings flash. You will practice iterating over the list by using a for loop. You will also create an iterator for the list and access the values from the iterator.\n",
    "\n",
    "- Create a for loop to loop over flash and print the values in the list. Use person as the loop variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n",
      "barry allen\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for person in flash:\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an iterator for the list flash and assign the result to superhero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "superhero = iter(flash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print each of the items from superhero using next() 4 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n"
     ]
    }
   ],
   "source": [
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barry allen\n"
     ]
    }
   ],
   "source": [
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1.3 Iterating over iterables (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things you learned about in this chapter is that not all iterables are actual lists. A couple of examples that we looked at are strings and the use of the range() function. In this exercise, we will focus on the range() function.\n",
    "\n",
    "You can use range() in a for loop as if it’s a list to be iterated over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that range() doesn’t actually create the list; instead, it creates a range object with an iterator that produces the values until it reaches the limit (in the example, until the value 4). If range() created the actual list, calling it with a value of 10100 may not work, especially since a number as big as that may go over a regular computer’s memory. The value 10100 is actually what’s called a Googol which is a 1 followed by a hundred 0s. That’s a huge number!\n",
    "\n",
    "Your task for this exercise is to show that calling range() with 10100 won’t actually pre-create the list.\n",
    "\n",
    "- Create an iterator object small_value over range(3) using the function iter()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterator trong Python là gì?\n",
    "Iterator ở khắp mọi nơi trong Python, bên trong các vòng lặp, comprehension, generator…\n",
    "\n",
    "Nó đơn giản chỉ là các đối tượng cho phép ta lấy từng phần tử, bất cứ khi nào bạn sử dụng vòng lặp hay các kĩ thuật để có được giá trị một nhóm phần tử ở một thời điểm nào đó.\n",
    "\n",
    "Về mặt kỹ thuật, Iterator trong Python phải thực hiện hai phương thức đặc biệt là __iter__() và __next__(), gọi chung là giao thức iterator (Iterator Protocol)\n",
    "\n",
    "Phương thức __iter__ trả về chính đối tượng iterator. Phương thức này được yêu cầu cài đặt cho cả đối tượng \"iterable\" và iterator để có thể sử dụng các câu lệnh for và in.\n",
    "Phương thức __next__ trả về phần tử tiếp theo. Nếu không còn phần tử nào nữa thì sẽ có lỗi StopIteration xảy ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for range(3): small_value\n",
    "small_value = iter(range(3))\n",
    "\n",
    "print(next(small_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(next(small_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(next(small_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using a for loop, iterate over range(3), printing the value for every iteration. Use num as the loop variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for num in range(3):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an iterator object googol over range(10 ** 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for range(10 ** 100): googol\n",
    "googol = iter(range(10 ** 100))\n",
    "\n",
    "# Print the first 5 values from googol\n",
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1.4 Iterators as function arguments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve been using the iter() function to get an iterator object, as well as the next() function to retrieve the values one by one from the iterator object.\n",
    "\n",
    "There are also functions that take iterators and iterables as arguments. For example, the list() and sum() functions return a list and the sum of elements, respectively.\n",
    "\n",
    "In this exercise, you will use these functions by passing an iterable from range() and then printing the results of the function calls.\n",
    "\n",
    "- Create a range object that would produce the values from 10 to 20 using range(). Assign the result to values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(10, 21)\n"
     ]
    }
   ],
   "source": [
    "# Create a range object: values\n",
    "values = range(10, 21)\n",
    "\n",
    "# Print the range object\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the list() function to create a list of values from the range object values. Assign the result to values_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of integers: values_list\n",
    "values_list = list(values)\n",
    "\n",
    "# Print values_list\n",
    "print(values_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the sum() function to get the sum of the values from 10 to 20 from the range object values. Assign the result to values_sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "# Get the sum of values: values_sum\n",
    "values_sum = sum(values)\n",
    "\n",
    "print(values_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Playing with iterators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.1 Using enumerate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re really getting the hang of using iterators, great job!\n",
    "\n",
    "You’ve just gained several new ideas on iterators from the last video and one of them is the enumerate() function. Recall that enumerate() returns an enumerate object that produces a sequence of tuples, and each of the tuples is an index-value pair.\n",
    "\n",
    "In this exercise, you are given a list of strings mutants and you will practice using enumerate() on it by printing out a list of tuples and unpacking the tuples using a for loop.\n",
    "\n",
    "- Create a list of tuples from mutants and assign the result to mutant_list. Make sure you generate the tuples using enumerate() and turn the result from it into a list using list()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: mutants\n",
    "mutants = ['charles xavier',\n",
    "           'bobby drake',\n",
    "           'kurt wagner',\n",
    "           'max eisenhardt',\n",
    "           'kitty pryde']\n",
    "\n",
    "# Create a list of tuples: mutant_list\n",
    "mutant_list = list(enumerate(mutants))\n",
    "\n",
    "print(mutant_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the first for loop by unpacking the tuples generated by calling enumerate() on mutants. Use index1 for the index and value1 for the value when unpacking the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 charles xavier\n",
      "1 bobby drake\n",
      "2 kurt wagner\n",
      "3 max eisenhardt\n",
      "4 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Unpack and pring the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the second for loop similarly as with the first, but this time change the starting index to start from 1 by passing it in as an argument to the start parameter of enumerate(). Use index2 for the index and value2 for the value when unpacking the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 charles xavier\n",
      "2 bobby drake\n",
      "3 kurt wagner\n",
      "4 max eisenhardt\n",
      "5 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Change the start index\n",
    "for index2, value2 in enumerate(mutants, start=1):\n",
    "    print(index2, value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.2 Using zip**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting function that you’ve learned is zip(), which takes any number of iterables and returns a zip object that is an iterator of tuples. If you wanted to print the values of a zip object, you can convert it into a list and then print it. Printing just a zip object will not return the values unless you unpack it first. In this exercise, you will explore this for yourself.\n",
    "\n",
    "Three lists of strings are pre-loaded: mutants, aliases, and powers. First, you will use list() and zip() on these lists to generate a list of tuples. Then, you will create a zip object using zip(). Finally, you will unpack this zip object in a for loop to print the values in each tuple. Observe the different output generated by printing the list of tuples, then the zip object, and finally, the tuple values in the for loop.\n",
    "\n",
    "- Using zip() with list(), create a list of tuples from the three lists mutants, aliases, and powers (in that order) and assign the result to mutant_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = ['prof x', 'iceman', 'nightcrawler','magneto','shadowcat']\n",
    "powers = ['telepathy','thermokinesis','teleportation','magnetokinesis','intangibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('charles xavier', 'prof x', 'telepathy'), ('bobby drake', 'iceman', 'thermokinesis'), ('kurt wagner', 'nightcrawler', 'teleportation'), ('max eisenhardt', 'magneto', 'magnetokinesis'), ('kitty pryde', 'shadowcat', 'intangibility')]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tuples: mutant_data\n",
    "mutant_data = list(zip(mutants, aliases, powers))\n",
    "\n",
    "print(mutant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using zip(), create a zip object called mutant_zip from the three lists mutants, aliases, and powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000002DE50107F00>\n"
     ]
    }
   ],
   "source": [
    "# Create a zip object using the three lists: mutant_zip\n",
    "mutant_zip = zip(mutants, aliases, powers)\n",
    "\n",
    "# Print the zip object\n",
    "print(mutant_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the for loop by unpacking the zip object you created and printing the tuple values. Use value1, value2, value3 for the values from each of mutants, aliases, and powers, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charles xavier prof x telepathy\n",
      "bobby drake iceman thermokinesis\n",
      "kurt wagner nightcrawler teleportation\n",
      "max eisenhardt magneto magnetokinesis\n",
      "kitty pryde shadowcat intangibility\n"
     ]
    }
   ],
   "source": [
    "# Unpack the zip object and print the tuple values\n",
    "for value1, value2, value3 in mutant_zip:\n",
    "    print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.3 Using * and zip to ‘unzip’**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know how to use zip() as well as how to print out values from a zip object. Excellent!\n",
    "\n",
    "Let’s play around with zip() a little more. There is no unzip function for doing the reverse of what zip() does. We can, however, reverse what has been zipped together by using zip() with a little help from !  unpacks an iterable such as a list or a tuple into positional arguments in a function call.\n",
    "\n",
    "In this exercise, you will use * in a call to zip() to unpack the tuples produced by zip().\n",
    "\n",
    "Two tuples of strings, mutants and powers have been pre-loaded.\n",
    "\n",
    "- Create a zip object by using zip() on mutants and powers, in that order. Assign the result to z1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the tuples in z1 by unpacking them into positional arguments using the * operator in a print() call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('charles xavier', 'telepathy') ('bobby drake', 'thermokinesis') ('kurt wagner', 'teleportation') ('max eisenhardt', 'magnetokinesis') ('kitty pryde', 'intangibility')\n"
     ]
    }
   ],
   "source": [
    "# Print the tuples in z1 by unpack with *\n",
    "print(*z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because the previous print() call would have exhausted the elements in z1, recreate the zip object you defined earlier and assign the result again to z1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ‘Unzip’ the tuples in z1 by unpacking them into positional arguments using the * operator in a zip() call. Assign the results to result1 and result2, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Upzip' the tuples in z1 by unpack with * and zip(): result1, result2\n",
    "result1, result2 = zip(*z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last print() statements prints the output of comparing result1 to mutants and result2 to powers. Click Submit Answer to see if the unpacked result1 and result2 are equivalent to mutants and powers, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check if unpacked tuples are equivalent to original tuples\n",
    "print(result1 == mutants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(result2 == powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 Using iterators to load large files into memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.1 Processing large amounts of Twitter data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the data we have to process reaches a size that is too much for a computer’s memory to handle. This is a common problem faced by data scientists. A solution to this is to process an entire data source chunk by chunk, instead of a single go all at once.\n",
    "\n",
    "In this exercise, you will do just that. You will process a large csv file of Twitter data in the same way that you processed ‘tweets.csv’ in Bringing it all together exercises of the prequel course, but this time, working on it in chunks of 10 entries at a time.\n",
    "\n",
    "If you are interested in learning how to access Twitter data so you can work with it on your own system, refer to Part 2 of the DataCamp course on Importing Data in Python.\n",
    "\n",
    "The pandas package has been imported as pd and the file ‘tweets.csv’ is in your current directory for your use.\n",
    "\n",
    "Be aware that this is real data from Twitter and as such there is always a risk that it may contain profanity or other offensive content (in this exercise, and any following exercises that also use real Twitter data).\n",
    "\n",
    "- Initialize an empty dictionary counts_dict for storing the results of processing the Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over the ‘tweets.csv’ file by using a for loop. Use the loop variable chunk and iterate over the call to pd.read_csv() with a chunksize of 10.\n",
    "- In the inner loop, iterate over the column ‘lang’ in chunk by using a for loop. Use the loop variable entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401759387648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>1459294817758</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401977319424</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>1459294817810</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402426236928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
       "      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n",
       "      <td>1459294817917</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402367561730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Your an idiot she shouldn't have tried to grab...</td>\n",
       "      <td>1459294817903</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402149416960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': 'The anti-America...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n",
       "      <td>1459294817851</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': -18000, 'profile_image_url_http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "3           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "4           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "3  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "4  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "3      False          low  NaN  714960402367561730  ...      7.149239e+17   \n",
       "4      False          low  NaN  714960402149416960  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "3         7.149239e+17              0      False   \n",
       "4                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'retweeted': False, 'text': 'The anti-America...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...  1459294817917     False   \n",
       "3  Your an idiot she shouldn't have tried to grab...  1459294817903     False   \n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...  1459294817851     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "3  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "4  {'utc_offset': -18000, 'profile_image_url_http...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd = df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Iterate over the file chunk by chunk\n",
    "for chunk in pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/tweets.csv', chunksize=10):\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in chunk['lang']:\n",
    "        if entry in counts_dict.keys():\n",
    "            counts_dict[entry] += 1\n",
    "        else:\n",
    "            counts_dict[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3.2 Extracting information for large amounts of Twitter data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job chunking out that file in the previous exercise. You now know how to deal with situations where you need to process a very large file and that’s a very useful skill to have!\n",
    "\n",
    "It’s good to know how to process a file in smaller, more manageable chunks, but it can become very tedious having to write and rewrite the same code for the same task each time. In this exercise, you will be making your code more reusable by putting your work in the last exercise in a function definition.\n",
    "\n",
    "The pandas package has been imported as pd and the file ‘tweets.csv’ is in your current directory for your use.\n",
    "\n",
    "- Define the function count_entries(), which has 3 parameters. The first parameter is csv_file for the filename, the second is c_size for the chunk size, and the last is colname for the column name.\n",
    "- Iterate over the file in csv_file file by using a for loop. Use the loop variable chunk and iterate over the call to pd.read_csv(), passing c_size to chunksize.\n",
    "- In the inner loop, iterate over the column given by colname in chunk by using a for loop. Use the loop variable entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(csv_file, c_size, colname):\n",
    "    \"\"\"Return a dictionary with counts of occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "    \n",
    "    # Iterate over the file chunk by chunk\n",
    "    for chunk in pd.read_csv(csv_file, chunksize = c_size):\n",
    "        \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "    \n",
    "    # Return counts_dict\n",
    "    return counts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call the count_entries() function by passing to it the filename ‘tweets.csv’, the size of chunks 10, and the name of the column to count, ‘lang’. Assign the result of the call to the variable result_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Call count_entries(): result_counts\n",
    "result_counts = count_entries('https://assets.datacamp.com/production/repositories/463/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv', 10, 'lang')\n",
    "\n",
    "# Print result_counts\n",
    "print(result_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5 List comprehensions and generators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you’ll build on your knowledge of iterators and be introduced to list comprehensions, which allow you to create complicated lists—and lists of lists—in one line of code! List comprehensions can dramatically simplify your code and make it more efficient, and will become a vital part of your Python data science toolbox. You’ll then learn about generators, which are extremely helpful when working with large sequences of data that you may not want to store in memory, but instead generate on the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 List comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1.1 Write a basic list comprehension**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will practice what you’ve learned from the video about writing list comprehensions. You will write a list comprehension and identify the output that will be produced.\n",
    "\n",
    "The following list has been pre-loaded in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctoc = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would a list comprehension that produces a list of the first character of each string in doctor look like? Note that the list comprehension uses doc as the iterator variable. What will the output be?\n",
    "\n",
    "- The list comprehension is [for doc in doctor: doc[0]] and produces the list [‘h’, ‘c’, ‘c’, ‘t’, ‘w’].\n",
    "- The list comprehension is [doc[0] in doctor] and produces the list [‘h’, ‘c’, ‘c’, ‘t’, ‘w’].\n",
    "- The list comprehension is [doc[0] in doctor] and produces the list [‘h’, ‘c’, ‘c’, ‘t’, ‘w’].\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1.2 List comprehension over iterables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know that list comprehensions can be built over iterables. Given the following objects below, which of these can we build list comprehensions over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']\n",
    "\n",
    "range(50)\n",
    "\n",
    "underwood = 'After all, we are nothing more or less than what we choose to reveal.'\n",
    "\n",
    "jean = '24601'\n",
    "\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "valjean = 24601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can build list comprehensions over all the objects except the string of number characters jean.\n",
    "- You can build list comprehensions over all the objects except the string lists doctor and flash.\n",
    "- You can build list comprehensions over all the objects except range(50).\n",
    "- You can build list comprehensions over all the objects except the integer object valjean.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1.3 Writing list comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all the knowledge necessary to begin writing list comprehensions! Your job in this exercise is to write a list comprehension that produces a list of the squares of the numbers ranging from 0 to 9.\n",
    "\n",
    "- Using the range of numbers from 0 to 9 as your iterable and i as your iterator variable, write a list comprehension that produces a list of numbers consisting of the squared values of i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list comprehension: squares\n",
    "squares = [i**2 for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1.4 Nested list comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! At this point, you have a good grasp of the basic syntax of list comprehensions. Let’s push your code-writing skills a little further. In this exercise, you will be writing a list comprehension within another list comprehension, or nested list comprehensions. It sounds a little tricky, but you can do it!\n",
    "\n",
    "Let’s step aside for a while from strings. One of the ways in which lists can be used are in representing multi-dimension objects such as matrices. Matrices can be represented as a list of lists in Python. For example a 5 x 5 matrix with values 0 to 4 in each row can be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0, 1, 2, 3, 4],\n",
    "          [0, 1, 2, 3, 4],\n",
    "          [0, 1, 2, 3, 4],\n",
    "          [0, 1, 2, 3, 4],\n",
    "          [0, 1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to recreate this matrix by using nested listed comprehensions. Recall that you can create one of the rows of the matrix with a single list comprehension. To create the list of lists, you simply have to supply the list comprehension as the output expression of the overall list comprehension:\n",
    "\n",
    "[[output expression] for iterator variable in iterable]\n",
    "\n",
    "Note that here, the output expression is itself a list comprehension.\n",
    "\n",
    "- In the inner list comprehension - that is, the output expression of the nested list comprehension - create a list of values from 0 to 4 using range(). Use col as the iterator variable.\n",
    "- In the iterable part of your nested list comprehension, use range() to count 5 rows - that is, create a list of values from 0 to 4. Use row as the iterator variable; note that you won’t be needing this variable to create values in the list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(5)] for row in range(5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Advanced comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.1 Using conditionals in comprehensions (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve been using list comprehensions to build lists of values, sometimes using operations to create these values.\n",
    "\n",
    "An interesting mechanism in list comprehensions is that you can also create lists with values that meet only a certain condition. One way of doing this is by using conditionals on iterator variables. In this exercise, you will do exactly that!\n",
    "\n",
    "Recall from the video that you can apply a conditional statement to test the iterator variable by adding an if statement in the optional predicate expression part after the for statement in the comprehension:\n",
    "\n",
    "[ output expression for iterator variable in iterable if predicate expression ].\n",
    "\n",
    "You will use this recipe to write a list comprehension for this exercise. You are given a list of strings fellowship and, using a list comprehension, you will create a list that only includes the members of fellowship that have 7 characters or more.\n",
    "\n",
    "- Use member as the iterator variable in the list comprehension. For the conditional, use len() to evaluate the iterator variable. Note that you only want strings with 7 characters or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'legolas', 'boromir']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry','aragorn','legolas','boromir','gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2.2 Using conditionals in comprehensions (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you used an if conditional statement in the predicate expression part of a list comprehension to evaluate an iterator variable. In this exercise, you will use an if-else statement on the output expression of the list.\n",
    "\n",
    "You will work on the same list, fellowship and, using a list comprehension and an if-else conditional statement in the output expression, create a list that keeps members of fellowship with 7 or more characters and replaces others with an empty string. Use member as the iterator variable in the list comprehension.\n",
    "\n",
    "- In the output expression, keep the string as-is if the number of characters is >= 7, else replace it with an empty string - that is, ’’ or ““."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'samwise', '', 'aragorn', 'legolas', 'boromir', '']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry','aragorn','legolas','boromir','gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member if len(member) >= 7 else '' for member in fellowship]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.3 Dict comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprehensions aren’t relegated merely to the world of lists. There are many other objects you can build using comprehensions, such as dictionaries, pervasive objects in Data Science. You will create a dictionary using the comprehension syntax for this exercise. In this case, the comprehension is called a dict comprehension.\n",
    "\n",
    "Recall that the main difference between a list comprehension and a dict comprehension is the use of curly braces {} instead of []. Additionally, members of the dictionary are created using a colon :, as in <key> : <value>.\n",
    "\n",
    "You are given a list of strings fellowship and, using a dict comprehension, create a dictionary with the members of the list as the keys and the length of each string as the corresponding values.\n",
    "\n",
    "Create a dict comprehension where the key is a string in fellowship and the value is the length of the string. Remember to use the syntax <key> : <value> in the output expression part of the comprehension to create the members of the dictionary. Use member as the iterator variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise','merry','aragorn','legolas','boromir','gimli']\n",
    "\n",
    "# Create dict comprehension: new_fellowship\n",
    "new_fellowship = { member: len(member) for member in fellowship}\n",
    "\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3 Introduction to generator expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3.1 List comprehensions vs. generators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve seen from the videos that list comprehensions and generator expressions look very similar in their syntax, except for the use of parentheses () in generator expressions and brackets [] in list comprehensions.\n",
    "\n",
    "In this exercise, you will recall the difference between list comprehensions and generators. To help with that task, the following code has been pre-loaded in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of strings\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# List comprehension\n",
    "fellow1 = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Generator expression\n",
    "fellow2 = (member for member in fellowship if len(member) >= 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to play around with fellow1 and fellow2 by figuring out their types and printing out their values. Based on your observations and what you can recall from the video, select from the options below the best description for the difference between list comprehensions and generators.\n",
    "\n",
    "- List comprehensions and generators are not different at all; they are just different ways of writing the same thing.\n",
    "- A list comprehension produces a list as output, a generator produces a generator object.\n",
    "- A list comprehension produces a list as output that can be iterated over, a generator produces a generator object that can’t be iterated over.\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3.2 Write your own generator expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are familiar with what generators and generator expressions are, as well as its difference from list comprehensions. In this exercise, you will practice building generator expressions on your own.\n",
    "\n",
    "Recall that generator expressions basically have the same syntax as list comprehensions, except that it uses parentheses () instead of brackets []; this should make things feel familiar! Furthermore, if you have ever iterated over a dictionary with .items(), or used the range() function, for example, you have already encountered and used generators before, without knowing it! When you use these functions, Python creates generators for you behind the scenes.\n",
    "\n",
    "Now, you will start simple by creating a generator object that produces numeric values.\n",
    "\n",
    "- Create a generator object that will produce values from 0 to 30. Assign the result to result and use num as the iterator variable in the generator expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator object: result\n",
    "result = (num for num in range(31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the first 5 values by using next() appropriately in print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(next(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(next(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(next(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(next(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the rest of the values by using a for loop to iterate over the generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Print the rest of the values\n",
    "for value in result:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3.3 Changing the output in generator expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! At this point, you already know how to write a basic generator expression. In this exercise, you will push this idea a little further by adding to the output expression of a generator expression. Because generator expressions and list comprehensions are so alike in syntax, this should be a familiar task for you!\n",
    "\n",
    "You are given a list of strings lannister and, using a generator expression, create a generator object that you will iterate over to print its values.\n",
    "\n",
    "- Write a generator expression that will generate the lengths of each string in lannister. Use person as the iterator variable. Assign the result to lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings: lannister\n",
    "lannister = ['cersei', 'jaime','tywin','tyrion','joffrey']\n",
    "\n",
    "# Create a generator object: lengths\n",
    "lengths = (len(person) for person in lannister)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supply the correct iterable in the for loop for printing the values in the generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Iterate over and print the values in lengths\n",
    "for value in lengths:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3.4 Build a generator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous exercises, you’ve dealt mainly with writing generator expressions, which uses comprehension syntax. Being able to use comprehension syntax for generator expressions made your work so much easier!\n",
    "\n",
    "Now, recall from the video that not only are there generator expressions, there are generator functions as well. Generator functions are functions that, like generator expressions, yield a series of values, instead of returning a single value. A generator function is defined as you do a regular function, but whenever it generates a value, it uses the keyword yield instead of return.\n",
    "\n",
    "In this exercise, you will create a generator function with a similar mechanism as the generator expression you defined in the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = (len(person) for person in lannister)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the function header for the function get_lengths() that has a single parameter, input_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings\n",
    "lannister = ['cersei','jaime','tywin','tyrion','joffrey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the for loop in the function definition, yield the length of the strings in input_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the iterable part of the for loop for printing the values generated by the get_lengths() generator function. Supply the call to get_lengths(), passing in the list lannister."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Print the values generatored by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.4 Wrapping up comprehensions and generators.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.4.1 List comprehensions for time-stamped data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now make use of what you’ve learned from this chapter to solve a simple data extraction problem. You will also be introduced to a data structure, the pandas Series, in this exercise. We won’t elaborate on it much here, but what you should know is that it is a data structure that you will be working with a lot of times when analyzing data from pandas DataFrames. You can think of DataFrame columns as single-dimension arrays called Series.\n",
    "\n",
    "In this exercise, you will be using a list comprehension to extract the time from time-stamped Twitter data. The pandas package has been imported as pd and the file ‘tweets.csv’ has been imported as the df DataFrame for your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401759387648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>1459294817758</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401977319424</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>1459294817810</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402426236928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
       "      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n",
       "      <td>1459294817917</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402367561730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Your an idiot she shouldn't have tried to grab...</td>\n",
       "      <td>1459294817903</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402149416960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': 'The anti-America...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n",
       "      <td>1459294817851</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': -18000, 'profile_image_url_http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "3           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "4           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "3  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "4  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "3      False          low  NaN  714960402367561730  ...      7.149239e+17   \n",
       "4      False          low  NaN  714960402149416960  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "3         7.149239e+17              0      False   \n",
       "4                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'retweeted': False, 'text': 'The anti-America...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...  1459294817917     False   \n",
       "3  Your an idiot she shouldn't have tried to grab...  1459294817903     False   \n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...  1459294817851     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "3  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "4  {'utc_offset': -18000, 'profile_image_url_http...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the column ‘created_at’ from df and assign the result to tweet_time. Fun fact: the extracted column in tweet_time here is a Series data structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Tue Mar 29 23:40:17 +0000 2016\n",
       "1     Tue Mar 29 23:40:17 +0000 2016\n",
       "2     Tue Mar 29 23:40:17 +0000 2016\n",
       "3     Tue Mar 29 23:40:17 +0000 2016\n",
       "4     Tue Mar 29 23:40:17 +0000 2016\n",
       "                   ...              \n",
       "95    Tue Mar 29 23:40:19 +0000 2016\n",
       "96    Tue Mar 29 23:40:19 +0000 2016\n",
       "97    Tue Mar 29 23:40:19 +0000 2016\n",
       "98    Tue Mar 29 23:40:19 +0000 2016\n",
       "99    Tue Mar 29 23:40:19 +0000 2016\n",
       "Name: created_at, Length: 100, dtype: object"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "tweet_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a list comprehension that extracts the time from each row in tweet_time. Each row is a string that represents a timestamp, and you will access the 12th to 19th characters in the string to extract the time. Use entry as the iterator variable and assign the result to tweet_clock_time. Remember that Python uses 0-based indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.4.2 Conditional list comprehensions for time-stamped data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, you’ve successfully extracted the data of interest, the time, from a pandas DataFrame! Let’s tweak your work further by adding a conditional that further specifies which entries to select.\n",
    "\n",
    "In this exercise, you will be using a list comprehension to extract the time from time-stamped Twitter data. You will add a conditional expression to the list comprehension so that you only select the times in which entry[17:19] is equal to ‘19’. The pandas package has been imported as pd and the file ‘tweets.csv’ has been imported as the df DataFrame for your use.\n",
    "\n",
    "- Extract the column ‘created_at’ from df and assign the result to tweet_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a list comprehension that extracts the time from each row in tweet_time. Each row is a string that represents a timestamp, and you will access the 12th to 19th characters in the string to extract the time. Use entry as the iterator variable and assign the result to tweet_clock_time. Additionally, add a conditional expression that checks whether entry[17:19] is equal to ‘19’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6 Bringing it all together!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter will allow you to apply your newly acquired skills toward wrangling and extracting meaningful information from a real-world dataset—the World Bank’s World Development Indicators. You’ll have the chance to write your own functions and list comprehensions as you work with iterators and generators to solidify your Python data science chops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 Welcome to the case study!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1.1 Dictionaries for data science**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you’ll use what you’ve learned about the zip() function and combine two lists into a dictionary.\n",
    "\n",
    "These lists are actually extracted from a bigger dataset file of world development indicators from the World Bank. For pedagogical purposes, we have pre-processed this dataset into the lists that you’ll be working with.\n",
    "\n",
    "The first list feature_names contains header names of the dataset and the second list row_vals contains actual values of a row from the dataset, corresponding to each of the header names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['CountryName', 'CountryCode', 'IndicatorName', 'IndicatorCode', 'Year', 'Value']\n",
    "row_vals = ['Arab World', 'ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT', '1960', '133.56090740552298']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a zip object by calling zip() and passing to it feature_names and row_vals. Assign the result to zipped_lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip lists: zipped_lists\n",
    "zipped_lists = zip(feature_names, row_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dictionary from the zipped_lists zip object by calling dict() with zipped_lists. Assign the resulting dictionary to rs_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary: rs_dict\n",
    "rs_dict = dict(zipped_lists)\n",
    "print(rs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1.2 Writing a function to help you**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you needed to repeat the same process done in the previous exercise to many, many rows of data. Rewriting your code again and again could become very tedious, repetitive, and unmaintainable.\n",
    "\n",
    "In this exercise, you will create a function to house the code you wrote earlier to make things easier and much more concise. Why? This way, you only need to call the function and supply the appropriate lists to create your dictionaries! Again, the lists feature_names and row_vals are preloaded and these contain the header names of the dataset and actual values of a row from the dataset, respectively.\n",
    "\n",
    "- Define the function lists2dict() with two parameters: first is list1 and second is list2.\n",
    "- Return the resulting dictionary rs_dict in lists2dict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists2dict()\n",
    "def lists2dict(list1, list2):\n",
    "    \"\"\"Return a dictionary where list1 provides\n",
    "    the keys and list2 provides the values.\"\"\"\n",
    "    \n",
    "    # Zip lists: zipped_lists\n",
    "    zipped_lists = zip(list1, list2)\n",
    "    \n",
    "    # Create a dictionary: rs_dict\n",
    "    rs_dict = dict(zipped_lists)\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return rs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call the lists2dict() function with the arguments feature_names and row_vals. Assign the result of the function call to rs_fxn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "# Call lists2dict: rs_fxn\n",
    "rs_fxn = lists2dict(feature_names, row_vals)\n",
    "\n",
    "# Print rs_fxn\n",
    "print(rs_fxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1.3 Using a list comprehension**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you’re going to use the lists2dict() function you defined in the last exercise to turn a bunch of lists into a list of dictionaries with the help of a list comprehension.\n",
    "\n",
    "The lists2dict() function has already been preloaded, together with a couple of lists, feature_names and row_lists. feature_names contains the header names of the World Bank dataset and row_lists is a list of lists, where each sublist is a list of actual values of a row from the dataset.\n",
    "\n",
    "Your goal is to use a list comprehension to generate a list of dicts, where the keys are the header names and the values are the row entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Arab World',\n",
       "  'ARB',\n",
       "  'Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
       "  'SP.ADO.TFRT',\n",
       "  '1960',\n",
       "  '133.56090740552298'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Age dependency ratio (% of working-age population)',\n",
       "  'SP.POP.DPND',\n",
       "  '1960',\n",
       "  '87.7976011532547'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Age dependency ratio, old (% of working-age population)',\n",
       "  'SP.POP.DPND.OL',\n",
       "  '1960',\n",
       "  '6.634579191565161'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Age dependency ratio, young (% of working-age population)',\n",
       "  'SP.POP.DPND.YG',\n",
       "  '1960',\n",
       "  '81.02332950839141'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Arms exports (SIPRI trend indicator values)',\n",
       "  'MS.MIL.XPRT.KD',\n",
       "  '1960',\n",
       "  '3000000.0'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Arms imports (SIPRI trend indicator values)',\n",
       "  'MS.MIL.MPRT.KD',\n",
       "  '1960',\n",
       "  '538000000.0'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Birth rate, crude (per 1,000 people)',\n",
       "  'SP.DYN.CBRT.IN',\n",
       "  '1960',\n",
       "  '47.697888095096395'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions (kt)',\n",
       "  'EN.ATM.CO2E.KT',\n",
       "  '1960',\n",
       "  '59563.9892169935'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions (metric tons per capita)',\n",
       "  'EN.ATM.CO2E.PC',\n",
       "  '1960',\n",
       "  '0.6439635478877049'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions from gaseous fuel consumption (% of total)',\n",
       "  'EN.ATM.CO2E.GF.ZS',\n",
       "  '1960',\n",
       "  '5.041291753975099'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions from liquid fuel consumption (% of total)',\n",
       "  'EN.ATM.CO2E.LF.ZS',\n",
       "  '1960',\n",
       "  '84.8514729446567'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions from liquid fuel consumption (kt)',\n",
       "  'EN.ATM.CO2E.LF.KT',\n",
       "  '1960',\n",
       "  '49541.707291032304'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'CO2 emissions from solid fuel consumption (% of total)',\n",
       "  'EN.ATM.CO2E.SF.ZS',\n",
       "  '1960',\n",
       "  '4.72698138789597'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Death rate, crude (per 1,000 people)',\n",
       "  'SP.DYN.CDRT.IN',\n",
       "  '1960',\n",
       "  '19.7544519237187'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Fertility rate, total (births per woman)',\n",
       "  'SP.DYN.TFRT.IN',\n",
       "  '1960',\n",
       "  '6.92402738655897'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Fixed telephone subscriptions',\n",
       "  'IT.MLT.MAIN',\n",
       "  '1960',\n",
       "  '406833.0'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Fixed telephone subscriptions (per 100 people)',\n",
       "  'IT.MLT.MAIN.P2',\n",
       "  '1960',\n",
       "  '0.6167005703199'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'Hospital beds (per 1,000 people)',\n",
       "  'SH.MED.BEDS.ZS',\n",
       "  '1960',\n",
       "  '1.9296220724398703'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'International migrant stock (% of population)',\n",
       "  'SM.POP.TOTL.ZS',\n",
       "  '1960',\n",
       "  '2.9906371279862403'],\n",
       " ['Arab World',\n",
       "  'ARB',\n",
       "  'International migrant stock, total',\n",
       "  'SM.POP.TOTL',\n",
       "  '1960',\n",
       "  '3324685.0']]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_lists = [['Arab World', 'ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT', '1960', '133.56090740552298'], ['Arab World', 'ARB', 'Age dependency ratio (% of working-age population)', 'SP.POP.DPND', '1960', '87.7976011532547'], ['Arab World', 'ARB', 'Age dependency ratio, old (% of working-age population)', 'SP.POP.DPND.OL', '1960', '6.634579191565161'], ['Arab World', 'ARB', 'Age dependency ratio, young (% of working-age population)', 'SP.POP.DPND.YG', '1960', '81.02332950839141'], ['Arab World', 'ARB', 'Arms exports (SIPRI trend indicator values)', 'MS.MIL.XPRT.KD', '1960', '3000000.0'], ['Arab World', 'ARB', 'Arms imports (SIPRI trend indicator values)', 'MS.MIL.MPRT.KD', '1960', '538000000.0'], ['Arab World', 'ARB', 'Birth rate, crude (per 1,000 people)', 'SP.DYN.CBRT.IN', '1960', '47.697888095096395'], ['Arab World', 'ARB', 'CO2 emissions (kt)', 'EN.ATM.CO2E.KT', '1960', '59563.9892169935'], ['Arab World', 'ARB', 'CO2 emissions (metric tons per capita)', 'EN.ATM.CO2E.PC', '1960', '0.6439635478877049'], ['Arab World', 'ARB', 'CO2 emissions from gaseous fuel consumption (% of total)', 'EN.ATM.CO2E.GF.ZS', '1960', '5.041291753975099'], ['Arab World', 'ARB', 'CO2 emissions from liquid fuel consumption (% of total)', 'EN.ATM.CO2E.LF.ZS', '1960', '84.8514729446567'], ['Arab World', 'ARB', 'CO2 emissions from liquid fuel consumption (kt)', 'EN.ATM.CO2E.LF.KT', '1960', '49541.707291032304'], ['Arab World', 'ARB', 'CO2 emissions from solid fuel consumption (% of total)', 'EN.ATM.CO2E.SF.ZS', '1960', '4.72698138789597'], ['Arab World', 'ARB', 'Death rate, crude (per 1,000 people)', 'SP.DYN.CDRT.IN', '1960', '19.7544519237187'], ['Arab World', 'ARB', 'Fertility rate, total (births per woman)', 'SP.DYN.TFRT.IN', '1960', '6.92402738655897'], ['Arab World', 'ARB', 'Fixed telephone subscriptions', 'IT.MLT.MAIN', '1960', '406833.0'], ['Arab World', 'ARB', 'Fixed telephone subscriptions (per 100 people)', 'IT.MLT.MAIN.P2', '1960', '0.6167005703199'], ['Arab World', 'ARB', 'Hospital beds (per 1,000 people)', 'SH.MED.BEDS.ZS', '1960', '1.9296220724398703'], ['Arab World', 'ARB', 'International migrant stock (% of population)', 'SM.POP.TOTL.ZS', '1960', '2.9906371279862403'], ['Arab World', 'ARB', 'International migrant stock, total', 'SM.POP.TOTL', '1960', '3324685.0']]\n",
    "row_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect the contents of row_lists by printing the first two lists in row_lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arab World', 'ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT', '1960', '133.56090740552298']\n"
     ]
    }
   ],
   "source": [
    "print(row_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arab World', 'ARB', 'Age dependency ratio (% of working-age population)', 'SP.POP.DPND', '1960', '87.7976011532547']\n"
     ]
    }
   ],
   "source": [
    "print(row_lists[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a list comprehension that generates a dictionary using lists2dict() for each sublist in row_lists. The keys are from the feature_names list and the values are the row entries in row_lists. Use sublist as your iterator variable and assign the resulting list of dictionaries to list_of_dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
       "  'IndicatorCode': 'SP.ADO.TFRT',\n",
       "  'Year': '1960',\n",
       "  'Value': '133.56090740552298'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Age dependency ratio (% of working-age population)',\n",
       "  'IndicatorCode': 'SP.POP.DPND',\n",
       "  'Year': '1960',\n",
       "  'Value': '87.7976011532547'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Age dependency ratio, old (% of working-age population)',\n",
       "  'IndicatorCode': 'SP.POP.DPND.OL',\n",
       "  'Year': '1960',\n",
       "  'Value': '6.634579191565161'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Age dependency ratio, young (% of working-age population)',\n",
       "  'IndicatorCode': 'SP.POP.DPND.YG',\n",
       "  'Year': '1960',\n",
       "  'Value': '81.02332950839141'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Arms exports (SIPRI trend indicator values)',\n",
       "  'IndicatorCode': 'MS.MIL.XPRT.KD',\n",
       "  'Year': '1960',\n",
       "  'Value': '3000000.0'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Arms imports (SIPRI trend indicator values)',\n",
       "  'IndicatorCode': 'MS.MIL.MPRT.KD',\n",
       "  'Year': '1960',\n",
       "  'Value': '538000000.0'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Birth rate, crude (per 1,000 people)',\n",
       "  'IndicatorCode': 'SP.DYN.CBRT.IN',\n",
       "  'Year': '1960',\n",
       "  'Value': '47.697888095096395'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions (kt)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.KT',\n",
       "  'Year': '1960',\n",
       "  'Value': '59563.9892169935'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions (metric tons per capita)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.PC',\n",
       "  'Year': '1960',\n",
       "  'Value': '0.6439635478877049'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions from gaseous fuel consumption (% of total)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.GF.ZS',\n",
       "  'Year': '1960',\n",
       "  'Value': '5.041291753975099'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions from liquid fuel consumption (% of total)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.LF.ZS',\n",
       "  'Year': '1960',\n",
       "  'Value': '84.8514729446567'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions from liquid fuel consumption (kt)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.LF.KT',\n",
       "  'Year': '1960',\n",
       "  'Value': '49541.707291032304'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'CO2 emissions from solid fuel consumption (% of total)',\n",
       "  'IndicatorCode': 'EN.ATM.CO2E.SF.ZS',\n",
       "  'Year': '1960',\n",
       "  'Value': '4.72698138789597'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Death rate, crude (per 1,000 people)',\n",
       "  'IndicatorCode': 'SP.DYN.CDRT.IN',\n",
       "  'Year': '1960',\n",
       "  'Value': '19.7544519237187'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Fertility rate, total (births per woman)',\n",
       "  'IndicatorCode': 'SP.DYN.TFRT.IN',\n",
       "  'Year': '1960',\n",
       "  'Value': '6.92402738655897'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Fixed telephone subscriptions',\n",
       "  'IndicatorCode': 'IT.MLT.MAIN',\n",
       "  'Year': '1960',\n",
       "  'Value': '406833.0'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Fixed telephone subscriptions (per 100 people)',\n",
       "  'IndicatorCode': 'IT.MLT.MAIN.P2',\n",
       "  'Year': '1960',\n",
       "  'Value': '0.6167005703199'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'Hospital beds (per 1,000 people)',\n",
       "  'IndicatorCode': 'SH.MED.BEDS.ZS',\n",
       "  'Year': '1960',\n",
       "  'Value': '1.9296220724398703'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'International migrant stock (% of population)',\n",
       "  'IndicatorCode': 'SM.POP.TOTL.ZS',\n",
       "  'Year': '1960',\n",
       "  'Value': '2.9906371279862403'},\n",
       " {'CountryName': 'Arab World',\n",
       "  'CountryCode': 'ARB',\n",
       "  'IndicatorName': 'International migrant stock, total',\n",
       "  'IndicatorCode': 'SM.POP.TOTL',\n",
       "  'Year': '1960',\n",
       "  'Value': '3324685.0'}]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "list_of_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look at the first two dictionaries in list_of_dicts by printing them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "print(list_of_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Age dependency ratio (% of working-age population)', 'IndicatorCode': 'SP.POP.DPND', 'Year': '1960', 'Value': '87.7976011532547'}\n"
     ]
    }
   ],
   "source": [
    "print(list_of_dicts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.1.4 Turning this all into a DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve zipped lists together, created a function to house your code, and even used the function in a list comprehension to generate a list of dictionaries. That was a lot of work and you did a great job!\n",
    "\n",
    "You will now use all of these to convert the list of dictionaries into a pandas DataFrame. You will see how convenient it is to generate a DataFrame from dictionaries with the DataFrame() function from the pandas package.\n",
    "\n",
    "The lists2dict() function, feature_names list, and row_lists list have been preloaded for this exercise.\n",
    "\n",
    "Go for it!\n",
    "\n",
    "- To use the DataFrame() function you need, first import the pandas package with the alias pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a DataFrame from the list of dictionaries in list_of_dicts by calling pd.DataFrame(). Assign the resulting DataFrame to df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn list of dicts into a DataFrame: df\n",
    "df = pd.DataFrame(list_of_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect the contents of df printing the head of the DataFrame. Head of the DataFrame df can be accessed by calling df.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CountryName CountryCode                                      IndicatorName  \\\n",
      "0  Arab World         ARB  Adolescent fertility rate (births per 1,000 wo...   \n",
      "1  Arab World         ARB  Age dependency ratio (% of working-age populat...   \n",
      "2  Arab World         ARB  Age dependency ratio, old (% of working-age po...   \n",
      "3  Arab World         ARB  Age dependency ratio, young (% of working-age ...   \n",
      "4  Arab World         ARB        Arms exports (SIPRI trend indicator values)   \n",
      "\n",
      "    IndicatorCode  Year               Value  \n",
      "0     SP.ADO.TFRT  1960  133.56090740552298  \n",
      "1     SP.POP.DPND  1960    87.7976011532547  \n",
      "2  SP.POP.DPND.OL  1960   6.634579191565161  \n",
      "3  SP.POP.DPND.YG  1960   81.02332950839141  \n",
      "4  MS.MIL.XPRT.KD  1960           3000000.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Using Python generators for streaming data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.2.1 Processing data in chunks (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, data sources can be so large in size that storing the entire dataset in memory becomes too resource-intensive. In this exercise, you will process the first 1000 rows of a file line by line, to create a dictionary of the counts of how many times each country appears in a column in the dataset.\n",
    "\n",
    "The csv file ‘world_dev_ind.csv’ is in your current directory for your use. To begin, you need to open a connection to this file using what is known as a context manager. For example, the command with open(‘datacamp.csv’) as datacamp binds the csv file ‘datacamp.csv’ as datacamp in the context manager. Here, the with statement is the context manager, and its purpose is to ensure that resources are efficiently allocated when opening a connection to a file.\n",
    "\n",
    "If you’d like to learn more about context managers, refer to the DataCamp course on Importing Data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use open() to bind the csv file ‘world_dev_ind.csv’ as file in the context manager.\n",
    "- Complete the for loop so that it iterates 1000 times to perform the loop body and process only the first 1000 rows of data of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arab World': 5, 'Caribbean small states': 5, 'Central Europe and the Baltics': 5, 'East Asia & Pacific (all income levels)': 5, 'East Asia & Pacific (developing only)': 5, 'Euro area': 5, 'Europe & Central Asia (all income levels)': 5, 'Europe & Central Asia (developing only)': 5, 'European Union': 5, 'Fragile and conflict affected situations': 5, 'Heavily indebted poor countries (HIPC)': 5, 'High income': 5, 'High income: nonOECD': 5, 'High income: OECD': 5, 'Latin America & Caribbean (all income levels)': 5, 'Latin America & Caribbean (developing only)': 5, 'Least developed countries: UN classification': 5, 'Low & middle income': 5, 'Low income': 5, 'Lower middle income': 5, 'Middle East & North Africa (all income levels)': 5, 'Middle East & North Africa (developing only)': 5, 'Middle income': 5, 'North America': 5, 'OECD members': 5, 'Other small states': 5, 'Pacific island small states': 5, 'Small states': 5, 'South Asia': 5, 'Sub-Saharan Africa (all income levels)': 5, 'Sub-Saharan Africa (developing only)': 5, 'Upper middle income': 5, 'World': 4, 'Afghanistan': 4, 'Albania': 4, 'Algeria': 4, 'American Samoa': 4, 'Andorra': 4, 'Angola': 4, 'Antigua and Barbuda': 4, 'Argentina': 4, 'Armenia': 4, 'Aruba': 4, 'Australia': 4, 'Austria': 4, 'Azerbaijan': 4, '\"Bahamas': 4, 'Bahrain': 4, 'Bangladesh': 4, 'Barbados': 4, 'Belarus': 4, 'Belgium': 4, 'Belize': 4, 'Benin': 4, 'Bermuda': 4, 'Bhutan': 4, 'Bolivia': 4, 'Bosnia and Herzegovina': 4, 'Botswana': 4, 'Brazil': 4, 'Brunei Darussalam': 4, 'Bulgaria': 4, 'Burkina Faso': 4, 'Burundi': 4, 'Cabo Verde': 4, 'Cambodia': 4, 'Cameroon': 4, 'Canada': 4, 'Cayman Islands': 4, 'Central African Republic': 4, 'Chad': 4, 'Channel Islands': 4, 'Chile': 4, 'China': 4, 'Colombia': 4, 'Comoros': 4, '\"Congo': 8, 'Costa Rica': 4, \"Cote d'Ivoire\": 4, 'Croatia': 4, 'Cuba': 4, 'Curacao': 4, 'Cyprus': 4, 'Czech Republic': 4, 'Denmark': 4, 'Djibouti': 4, 'Dominica': 4, 'Dominican Republic': 4, 'Ecuador': 4, '\"Egypt': 4, 'El Salvador': 4, 'Equatorial Guinea': 4, 'Eritrea': 4, 'Estonia': 4, 'Ethiopia': 4, 'Faeroe Islands': 4, 'Fiji': 4, 'Finland': 4, 'France': 4, 'French Polynesia': 4, 'Gabon': 4, '\"Gambia': 4, 'Georgia': 4, 'Germany': 4, 'Ghana': 4, 'Greece': 4, 'Greenland': 4, 'Grenada': 4, 'Guam': 4, 'Guatemala': 4, 'Guinea': 4, 'Guinea-Bissau': 4, 'Guyana': 4, 'Haiti': 4, 'Honduras': 4, '\"Hong Kong SAR': 4, 'Hungary': 4, 'Iceland': 4, 'India': 4, 'Indonesia': 4, '\"Iran': 4, 'Iraq': 4, 'Ireland': 4, 'Isle of Man': 4, 'Israel': 4, 'Italy': 4, 'Jamaica': 4, 'Japan': 4, 'Jordan': 4, 'Kazakhstan': 4, 'Kenya': 4, 'Kiribati': 4, '\"Korea': 8, 'Kuwait': 4, 'Kyrgyz Republic': 4, 'Lao PDR': 4, 'Latvia': 4, 'Lebanon': 4, 'Lesotho': 4, 'Liberia': 4, 'Libya': 4, 'Liechtenstein': 4, 'Lithuania': 4, 'Luxembourg': 4, '\"Macao SAR': 4, '\"Macedonia': 4, 'Madagascar': 4, 'Malawi': 4, 'Malaysia': 4, 'Maldives': 4, 'Mali': 4, 'Malta': 4, 'Marshall Islands': 4, 'Mauritania': 4, 'Mauritius': 4, 'Mexico': 4, '\"Micronesia': 4, 'Moldova': 4, 'Monaco': 4, 'Mongolia': 4, 'Montenegro': 4, 'Morocco': 4, 'Mozambique': 4, 'Myanmar': 4, 'Namibia': 4, 'Nepal': 4, 'Netherlands': 4, 'New Caledonia': 4, 'New Zealand': 4, 'Nicaragua': 4, 'Niger': 4, 'Nigeria': 4, 'Northern Mariana Islands': 4, 'Norway': 4, 'Oman': 4, 'Pakistan': 4, 'Palau': 4, 'Panama': 4, 'Papua New Guinea': 4, 'Paraguay': 4, 'Peru': 4, 'Philippines': 4, 'Poland': 4, 'Portugal': 4, 'Puerto Rico': 4, 'Qatar': 4, 'Romania': 4, 'Russian Federation': 4, 'Rwanda': 4, 'Samoa': 4, 'San Marino': 4, 'Sao Tome and Principe': 4, 'Saudi Arabia': 4, 'Senegal': 4, 'Seychelles': 4, 'Sierra Leone': 4, 'Singapore': 4, 'Slovak Republic': 4, 'Slovenia': 4, 'Solomon Islands': 4, 'Somalia': 4, 'South Africa': 4, 'South Sudan': 4, 'Spain': 4, 'Sri Lanka': 4, 'St. Kitts and Nevis': 4, 'St. Lucia': 4, 'St. Vincent and the Grenadines': 4, 'Sudan': 4, 'Suriname': 4, 'Swaziland': 4, 'Sweden': 4, 'Switzerland': 4, 'Syrian Arab Republic': 4, 'Tajikistan': 4, 'Tanzania': 4, 'Thailand': 4, 'Timor-Leste': 4, 'Togo': 4, 'Tonga': 4, 'Trinidad and Tobago': 4, 'Tunisia': 4, 'Turkey': 4, 'Turkmenistan': 4, 'Turks and Caicos Islands': 4, 'Tuvalu': 4, 'Uganda': 4, 'Ukraine': 4, 'United Arab Emirates': 4, 'United Kingdom': 4, 'United States': 4, 'Uruguay': 4, 'Uzbekistan': 4, 'Vanuatu': 4, '\"Venezuela': 4, 'Vietnam': 4, 'Virgin Islands (U.S.)': 4, '\"Yemen': 4, 'Zambia': 4, 'Zimbabwe': 4}\n"
     ]
    }
   ],
   "source": [
    "# Open a connection to the file\n",
    "with open(r'C:\\Users\\Quan Thi Thanh Hoa\\AppData\\AI and ML, RL\\world_ind_pop_data.csv') as file:\n",
    "    \n",
    "    # Skip the column names\n",
    "    file.readline()\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "    \n",
    "    # Process only the first 1000 rows\n",
    "    for j in range(0, 1000):\n",
    "        \n",
    "        # Split the current line into a list: line\n",
    "        line = file.readline().split(',')\n",
    "        \n",
    "        # Get the value for the first column: first_col\n",
    "        first_col = line[0]\n",
    "        \n",
    "        # If the column value is in the dic, increment its value\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "            \n",
    "        # Else, add to the dict and set value to 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.2.2 Writing a generator to load data in chunks (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you processed a file line by line for a given number of lines. What if, however, you want to do this for the entire file?\n",
    "\n",
    "In this case, it would be useful to use generators. Generators allow users to lazily evaluate data. This concept of lazy evaluation is useful when you have to deal with very large datasets because it lets you generate values in an efficient manner by yielding only chunks of data at a time instead of the whole thing at once.\n",
    "\n",
    "In this exercise, you will define a generator function read_large_file() that produces a generator object which yields a single line from a file each time next() is called on it. The csv file ‘world_dev_ind.csv’ is in your current directory for your use.\n",
    "\n",
    "Note that when you open a connection to a file, the resulting file object is already a generator! So out in the wild, you won’t have to explicitly create generator objects in cases such as this. However, for pedagogical reasons, we are having you practice how to do this here with the read_large_file() function. Go for it!\n",
    "\n",
    "- In the function read_large_file(), read a line from file_object by using the method readline(). Assign the result to data.\n",
    "- In the function read_large_file(), yield the line read from the file data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yield là một keyworrd trong Python được sử dụng để trả về giá trị của hàm mà không hủy đi trạng thái của các biến trong hàm. Nó sẽ tạm giữ trạng thái của các biến ngay tại vị trí yield đầu tiên, để những lần goi hàm tiếp theo sẽ tiếp tục xử lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "    \n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "        \n",
    "        # Read a line from the file: data\n",
    "        data = file_object.readline()\n",
    "        \n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "        \n",
    "        # Yield the line of data\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the context manager, create a generator object gen_file by calling your generator function read_large_file() and passing file to it.\n",
    "- Print the first three lines produced by the generator object gen_file using next()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryName,CountryCode,Year,Total Population,Urban population (% of total)\n",
      "\n",
      "Arab World,ARB,1960,92495902.0,31.285384211605397\n",
      "\n",
      "Caribbean small states,CSS,1960,4190810.0,31.5974898513652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\Quan Thi Thanh Hoa\\AppData\\AI and ML, RL\\world_ind_pop_data.csv') as file:\n",
    "    \n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "    \n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful work! Note that since a file object is already a generator, you don’t have to explicitly create a generator object with your read_large_file() function. However, it is still good to practice how to create generators - well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.2.3 Writing a generator to load data in chunks (3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You’ve just created a generator function that you can use to help you process large files.\n",
    "\n",
    "Now let’s use your generator function to process the World Bank dataset like you did previously. You will process the file line by line, to create a dictionary of the counts of how many times each country appears in a column in the dataset. For this exercise, however, you won’t process just 1000 rows of data, you’ll process the entire dataset!\n",
    "\n",
    "The generator function read_large_file() and the csv file ‘world_dev_ind.csv’ are preloaded and ready for your use. Go for it!\n",
    "\n",
    "- Bind the file ‘world_dev_ind.csv’ to file in the context manager with open().\n",
    "- Complete the for loop so that it iterates over the generator from the call to read_large_file() to process all the rows of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 1, 'Arab World': 55, 'Caribbean small states': 55, 'Central Europe and the Baltics': 55, 'East Asia & Pacific (all income levels)': 55, 'East Asia & Pacific (developing only)': 55, 'Euro area': 55, 'Europe & Central Asia (all income levels)': 55, 'Europe & Central Asia (developing only)': 55, 'European Union': 55, 'Fragile and conflict affected situations': 55, 'Heavily indebted poor countries (HIPC)': 55, 'High income': 55, 'High income: nonOECD': 55, 'High income: OECD': 55, 'Latin America & Caribbean (all income levels)': 55, 'Latin America & Caribbean (developing only)': 55, 'Least developed countries: UN classification': 55, 'Low & middle income': 55, 'Low income': 55, 'Lower middle income': 55, 'Middle East & North Africa (all income levels)': 55, 'Middle East & North Africa (developing only)': 55, 'Middle income': 55, 'North America': 55, 'OECD members': 55, 'Other small states': 55, 'Pacific island small states': 55, 'Small states': 55, 'South Asia': 55, 'Sub-Saharan Africa (all income levels)': 55, 'Sub-Saharan Africa (developing only)': 55, 'Upper middle income': 55, 'World': 55, 'Afghanistan': 55, 'Albania': 55, 'Algeria': 55, 'American Samoa': 55, 'Andorra': 55, 'Angola': 55, 'Antigua and Barbuda': 55, 'Argentina': 55, 'Armenia': 55, 'Aruba': 55, 'Australia': 55, 'Austria': 55, 'Azerbaijan': 55, '\"Bahamas': 55, 'Bahrain': 55, 'Bangladesh': 55, 'Barbados': 55, 'Belarus': 55, 'Belgium': 55, 'Belize': 55, 'Benin': 55, 'Bermuda': 55, 'Bhutan': 55, 'Bolivia': 55, 'Bosnia and Herzegovina': 55, 'Botswana': 55, 'Brazil': 55, 'Brunei Darussalam': 55, 'Bulgaria': 55, 'Burkina Faso': 55, 'Burundi': 55, 'Cabo Verde': 55, 'Cambodia': 55, 'Cameroon': 55, 'Canada': 55, 'Cayman Islands': 55, 'Central African Republic': 55, 'Chad': 55, 'Channel Islands': 55, 'Chile': 55, 'China': 55, 'Colombia': 55, 'Comoros': 55, '\"Congo': 110, 'Costa Rica': 55, \"Cote d'Ivoire\": 55, 'Croatia': 55, 'Cuba': 55, 'Curacao': 55, 'Cyprus': 55, 'Czech Republic': 55, 'Denmark': 55, 'Djibouti': 55, 'Dominica': 55, 'Dominican Republic': 55, 'Ecuador': 55, '\"Egypt': 55, 'El Salvador': 55, 'Equatorial Guinea': 55, 'Eritrea': 55, 'Estonia': 55, 'Ethiopia': 55, 'Faeroe Islands': 55, 'Fiji': 55, 'Finland': 55, 'France': 55, 'French Polynesia': 55, 'Gabon': 55, '\"Gambia': 55, 'Georgia': 55, 'Germany': 55, 'Ghana': 55, 'Greece': 55, 'Greenland': 55, 'Grenada': 55, 'Guam': 55, 'Guatemala': 55, 'Guinea': 55, 'Guinea-Bissau': 55, 'Guyana': 55, 'Haiti': 55, 'Honduras': 55, '\"Hong Kong SAR': 55, 'Hungary': 55, 'Iceland': 55, 'India': 55, 'Indonesia': 55, '\"Iran': 55, 'Iraq': 55, 'Ireland': 55, 'Isle of Man': 55, 'Israel': 55, 'Italy': 55, 'Jamaica': 55, 'Japan': 55, 'Jordan': 55, 'Kazakhstan': 55, 'Kenya': 55, 'Kiribati': 55, '\"Korea': 110, 'Kuwait': 52, 'Kyrgyz Republic': 55, 'Lao PDR': 55, 'Latvia': 55, 'Lebanon': 55, 'Lesotho': 55, 'Liberia': 55, 'Libya': 55, 'Liechtenstein': 55, 'Lithuania': 55, 'Luxembourg': 55, '\"Macao SAR': 55, '\"Macedonia': 55, 'Madagascar': 55, 'Malawi': 55, 'Malaysia': 55, 'Maldives': 55, 'Mali': 55, 'Malta': 55, 'Marshall Islands': 55, 'Mauritania': 55, 'Mauritius': 55, 'Mexico': 55, '\"Micronesia': 55, 'Moldova': 55, 'Monaco': 55, 'Mongolia': 55, 'Montenegro': 55, 'Morocco': 55, 'Mozambique': 55, 'Myanmar': 55, 'Namibia': 55, 'Nepal': 55, 'Netherlands': 55, 'New Caledonia': 55, 'New Zealand': 55, 'Nicaragua': 55, 'Niger': 55, 'Nigeria': 55, 'Northern Mariana Islands': 55, 'Norway': 55, 'Oman': 55, 'Pakistan': 55, 'Palau': 55, 'Panama': 55, 'Papua New Guinea': 55, 'Paraguay': 55, 'Peru': 55, 'Philippines': 55, 'Poland': 55, 'Portugal': 55, 'Puerto Rico': 55, 'Qatar': 55, 'Romania': 55, 'Russian Federation': 55, 'Rwanda': 55, 'Samoa': 55, 'San Marino': 55, 'Sao Tome and Principe': 55, 'Saudi Arabia': 55, 'Senegal': 55, 'Seychelles': 55, 'Sierra Leone': 55, 'Singapore': 55, 'Slovak Republic': 55, 'Slovenia': 55, 'Solomon Islands': 55, 'Somalia': 55, 'South Africa': 55, 'South Sudan': 55, 'Spain': 55, 'Sri Lanka': 55, 'St. Kitts and Nevis': 55, 'St. Lucia': 55, 'St. Vincent and the Grenadines': 55, 'Sudan': 55, 'Suriname': 55, 'Swaziland': 55, 'Sweden': 55, 'Switzerland': 55, 'Syrian Arab Republic': 55, 'Tajikistan': 55, 'Tanzania': 55, 'Thailand': 55, 'Timor-Leste': 55, 'Togo': 55, 'Tonga': 55, 'Trinidad and Tobago': 55, 'Tunisia': 55, 'Turkey': 55, 'Turkmenistan': 55, 'Turks and Caicos Islands': 55, 'Tuvalu': 55, 'Uganda': 55, 'Ukraine': 55, 'United Arab Emirates': 55, 'United Kingdom': 55, 'United States': 55, 'Uruguay': 55, 'Uzbekistan': 55, 'Vanuatu': 55, '\"Venezuela': 55, 'Vietnam': 55, 'Virgin Islands (U.S.)': 55, '\"Yemen': 55, 'Zambia': 55, 'Zimbabwe': 55, 'Serbia': 25, 'West Bank and Gaza': 25, 'Sint Maarten (Dutch part)': 17}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "with open(r'C:\\Users\\Quan Thi Thanh Hoa\\AppData\\AI and ML, RL\\world_ind_pop_data.csv') as file:\n",
    "    \n",
    "    # Iterater over the generator from read_large_file()\n",
    "    for line in read_large_file(file):\n",
    "        \n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "        \n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Using pandas’ read_csv iterator for streaming data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.3.1 Writing an iterator to load data in chunks (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to read data too large to store in memory in chunks is to read the file in as DataFrames of a certain length, say, 100. For example, with the pandas package (imported as pd), you can do pd.read_csv(filename, chunksize=100). This creates an iterable reader object, which means that you can use next() on it.\n",
    "\n",
    "In this exercise, you will read a file in small DataFrame chunks with read_csv(). You’re going to use the World Bank Indicators data ‘ind_pop.csv’, available in your current directory, to look at the urban population indicator for numerous countries and years.\n",
    "\n",
    "- Use pd.read_csv() to read in ‘ind_pop.csv’ in chunks of size 10. Assign the result to df_reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize reader object: df_reader\n",
    "df_reader = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/world_ind_pop_data.csv', chunksize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the first two chunks from df_reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 CountryName CountryCode  Year  \\\n",
      "0                                 Arab World         ARB  1960   \n",
      "1                     Caribbean small states         CSS  1960   \n",
      "2             Central Europe and the Baltics         CEB  1960   \n",
      "3    East Asia & Pacific (all income levels)         EAS  1960   \n",
      "4      East Asia & Pacific (developing only)         EAP  1960   \n",
      "5                                  Euro area         EMU  1960   \n",
      "6  Europe & Central Asia (all income levels)         ECS  1960   \n",
      "7    Europe & Central Asia (developing only)         ECA  1960   \n",
      "8                             European Union         EUU  1960   \n",
      "9   Fragile and conflict affected situations         FCS  1960   \n",
      "\n",
      "   Total Population  Urban population (% of total)  \n",
      "0      9.249590e+07                      31.285384  \n",
      "1      4.190810e+06                      31.597490  \n",
      "2      9.140158e+07                      44.507921  \n",
      "3      1.042475e+09                      22.471132  \n",
      "4      8.964930e+08                      16.917679  \n",
      "5      2.653965e+08                      62.096947  \n",
      "6      6.674890e+08                      55.378977  \n",
      "7      1.553174e+08                      38.066129  \n",
      "8      4.094985e+08                      61.212898  \n",
      "9      1.203546e+08                      17.891972  \n"
     ]
    }
   ],
   "source": [
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      CountryName CountryCode  Year  \\\n",
      "10         Heavily indebted poor countries (HIPC)         HPC  1960   \n",
      "11                                    High income         HIC  1960   \n",
      "12                           High income: nonOECD         NOC  1960   \n",
      "13                              High income: OECD         OEC  1960   \n",
      "14  Latin America & Caribbean (all income levels)         LCN  1960   \n",
      "15    Latin America & Caribbean (developing only)         LAC  1960   \n",
      "16   Least developed countries: UN classification         LDC  1960   \n",
      "17                            Low & middle income         LMY  1960   \n",
      "18                                     Low income         LIC  1960   \n",
      "19                            Lower middle income         LMC  1960   \n",
      "\n",
      "    Total Population  Urban population (% of total)  \n",
      "10      1.624912e+08                      12.236046  \n",
      "11      9.075975e+08                      62.680332  \n",
      "12      1.866767e+08                      56.107863  \n",
      "13      7.209208e+08                      64.285435  \n",
      "14      2.205642e+08                      49.284688  \n",
      "15      1.776822e+08                      44.863308  \n",
      "16      2.410728e+08                       9.616261  \n",
      "17      2.127373e+09                      21.272894  \n",
      "18      1.571884e+08                      11.498396  \n",
      "19      9.429116e+08                      19.810513  \n"
     ]
    }
   ],
   "source": [
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.3.2 Writing an iterator to load data in chunks (2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you used read_csv() to read in DataFrame chunks from a large dataset. In this exercise, you will read in a file using a bigger DataFrame chunk size and then process the data from the first chunk.\n",
    "\n",
    "To process the data, you will create another DataFrame composed of only the rows from a specific country. You will then zip together two of the columns from the new DataFrame, ‘Total Population’ and ‘Urban population (% of total)’. Finally, you will create a list of tuples from the zip object, where each tuple is composed of a value from each of the two columns mentioned.\n",
    "\n",
    "You’re going to use the data from ‘ind_pop_data.csv’, available in your current directory. pandas has been imported as pd.\n",
    "\n",
    "- Use pd.read_csv() to read in the file in ‘ind_pop_data.csv’ in chunks of size 1000. Assign the result to urb_pop_reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_pop_reader = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/world_ind_pop_data.csv', chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the first DataFrame chunk from the iterable urb_pop_reader and assign this to df_urb_pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               CountryName CountryCode  Year  \\\n",
      "0                               Arab World         ARB  1960   \n",
      "1                   Caribbean small states         CSS  1960   \n",
      "2           Central Europe and the Baltics         CEB  1960   \n",
      "3  East Asia & Pacific (all income levels)         EAS  1960   \n",
      "4    East Asia & Pacific (developing only)         EAP  1960   \n",
      "\n",
      "   Total Population  Urban population (% of total)  \n",
      "0      9.249590e+07                      31.285384  \n",
      "1      4.190810e+06                      31.597490  \n",
      "2      9.140158e+07                      44.507921  \n",
      "3      1.042475e+09                      22.471132  \n",
      "4      8.964930e+08                      16.917679  \n"
     ]
    }
   ],
   "source": [
    "# Get the first DataFrame: df_urb_pop\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "# Check out the head of the DataFrame\n",
    "print(df_urb_pop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select only the rows of df_urb_pop that have a ‘CountryCode’ of ‘CEB’. To do this, compare whether df_urb_pop[‘CountryCode’] is equal to ‘CEB’ within the square brackets in df_urb_pop[____]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out specific country: df_pop_ceb\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using zip(), zip together the ‘Total Population’ and ‘Urban population (% of total)’ columns of df_pop_ceb. Assign the resulting zip object to pops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(91401583.0, 44.5079211390026), (92237118.0, 45.206665319194), (93014890.0, 45.866564696018), (93845749.0, 46.5340927663649), (94722599.0, 47.2087429803526)]\n"
     ]
    }
   ],
   "source": [
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Total Population'],\n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "# Turn zip object into list: pops_list\n",
    "pops_list = list(pops)\n",
    "\n",
    "print(pops_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.3.3 Writing an iterator to load data in chunks (3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re getting used to reading and processing data in chunks by now. Let’s push your skills a little further by adding a column to a DataFrame.\n",
    "\n",
    "Starting from the code of the previous exercise, you will be using a list comprehension to create the values for a new column ‘Total Urban Population’ from the list of tuples that you generated earlier. Recall from the previous exercise that the first and second elements of each tuple consist of, respectively, values from the columns ‘Total Population’ and ‘Urban population (% of total)’. The values in this new column ‘Total Urban Population’, therefore, are the product of the first and second element in each tuple. Furthermore, because the 2nd element is a percentage, you need to divide the entire result by 100, or alternatively, multiply it by 0.01.\n",
    "\n",
    "You will also plot the data from this new column to create a visualization of the urban population data.\n",
    "\n",
    "The packages pandas and matplotlib.pyplot have been imported as pd and plt respectively for your use.\n",
    "\n",
    "- Write a list comprehension to generate a list of values from pops_list for the new column ‘Total Urban Population’. The output expression should be the product of the first and second element in each tuple in pops_list. Because the 2nd element is a percentage, you also need to either multiply the result by 0.01 or divide it by 100. In addition, note that the column ‘Total Urban Population’ should only be able to take on integer values. To ensure this, make sure you cast the output expression to an integer with int()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\316358712.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] ** 0.01) for tup in pops_list]\n"
     ]
    }
   ],
   "source": [
    "# Code from previous exercise\n",
    "urb_pop_reader = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/world_ind_pop_data.csv', chunksize=1000)\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "pops = zip(df_pop_ceb['Total Population'],\n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] ** 0.01) for tup in pops_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a scatter plot where the x-axis are values from the ‘Year’ column and the y-axis are values from the ‘Total Urban Population’ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot urban population data\n",
    "df_pop_ceb.plot(kind='scatter', x='Year',y='Total Urban Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.3.4 Writing an iterator to load data in chunks (4)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercises, you’ve only processed the data from the first DataFrame chunk. This time, you will aggregate the results over all the DataFrame chunks in the dataset. This basically means you will be processing the entire dataset now. This is neat because you’re going to be able to process the entire large dataset by just working on smaller pieces of it!\n",
    "\n",
    "You’re going to use the data from ‘ind_pop_data.csv’, available in your current directory. The packages pandas and matplotlib.pyplot have been imported as pd and plt respectively for your use.\n",
    "\n",
    "- Initialize an empty DataFrame data using pd.DataFrame()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_pop_reader = pd.read_csv('https://raw.githubusercontent.com/cliex159/DatacampDataset/main/PythonDataScienceToolbox/world_ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the for loop, iterate over urb_pop_reader to be able to process all the DataFrame chunks in the dataset.\n",
    "- Using the method append() of the DataFrame data, append df_pop_ceb to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\3145004202.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each DataFrame chunk\n",
    "for df_urb_pop in urb_pop_reader:\n",
    "\n",
    "    # Check out specific country: df_pop_ceb\n",
    "    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "    # Zip DataFrame columns of interest: pops\n",
    "    pops = zip(df_pop_ceb['Total Population'],\n",
    "                df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "    # Turn zip object into list: pops_list\n",
    "    pops_list = list(pops)\n",
    "\n",
    "    # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    \n",
    "    # Append DataFrame chunk to data: data\n",
    "    data = data.append(df_pop_ceb)\n",
    "\n",
    "# Plot urban population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3.5 Writing an iterator to load data in chunks (5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last leg. You’ve learned a lot about processing a large dataset in chunks. In this last exercise, you will put all the code for processing the data into a single function so that you can reuse the code without having to rewrite the same things all over again.\n",
    "\n",
    "You’re going to define the function plot_pop() which takes two arguments: the filename of the file to be processed, and the country code of the rows you want to process in the dataset.\n",
    "\n",
    "Because all of the previous code you’ve written in the previous exercises will be housed in plot_pop(), calling the function already does the following:\n",
    "\n",
    "- Loading of the file chunk by chunk,\n",
    "- Creating the new column of urban population values, and\n",
    "- Plotting the urban population data.\n",
    "That’s a lot of work, but the function now makes it convenient to repeat the same process for whatever file and country code you want to process and visualize!\n",
    "\n",
    "You’re going to use the data from ‘ind_pop_data.csv’, available in your current directory. The packages pandas and matplotlib.pyplot has been imported as pd and plt respectively for your use.\n",
    "\n",
    "After you are done, take a moment to look at the plots and reflect on the new skills you have acquired. The journey doesn’t end here! If you have enjoyed working with this data, you can continue exploring it using the pre-processed version available on Kaggle.\n",
    "\n",
    "- Define the function plot_pop() that has two arguments: first is filename for the file to process and second is country_code for the country to be processed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot_pop()\n",
    "def plot_pop(filename, country_code):\n",
    "\n",
    "    # Initialize reader object: urb_pop_reader\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "\n",
    "    # Initialize empty DataFrame: data\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each DataFrame chunk\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        # Check out specific country: df_pop_ceb\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "\n",
    "        # Zip DataFrame columns of interest: pops\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "        # Turn zip object into list: pops_list\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    \n",
    "        # Append DataFrame chunk to data: data\n",
    "        data = data.append(df_pop_ceb)\n",
    "\n",
    "    # Plot urban population data\n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call plot_pop() to process the data for country code ‘CEB’ in the file ‘ind_pop_data.csv’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the filename: fn\n",
    "fn = 'https://assets.datacamp.com/production/repositories/464/datasets/2175fef4b3691db03449bbc7ddffb740319c1131/world_ind_pop_data.csv'\n",
    "\n",
    "# Call plot_pop for country code 'CEB'\n",
    "plot_pop(fn, 'CEB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
      "C:\\Users\\Quan Thi Thanh Hoa\\AppData\\Local\\Temp\\ipykernel_25332\\653901710.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df_pop_ceb)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call plot_pop for country code 'ARB'\n",
    "plot_pop(fn, 'ARB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ad7f758c7f2ebdda2cc4f553f1363ed8fbfe288e0aece9aaf2ec73dff90b611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
